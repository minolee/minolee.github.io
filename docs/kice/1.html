<h1 id="ai-">AI 직무 평가: 주요 주제 요약</h1>
<h2 id="-">데이터 전처리 기법</h2>
<ul>
<li><strong>데이터 수집:</strong> AI 모델의 성능은 데이터 품질에 크게 의존하므로, 다양한 원천에서 <strong>풍부하고 대표성 있는 데이터를 수집</strong>하는 것이 중요합니다. 수집한 원본 데이터는 보통 오류와 잡음, 누락치로 <strong>매우 지저분</strong>하며 실제 분석에 바로 사용할 수 없기 때문에, 데이터 과학자의 업무 시간 중 약 80%가 <strong>데이터 전처리</strong>에 소요된다고 알려져 있습니다<a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=This%20is%20why%20data%20preprocessing,to%20data%20preprocessing%20and%20management">[1]</a>.</li>
<li><strong>데이터 정제:</strong> 수집된 원시 데이터의 <strong>오류를 수정</strong>하고 일관성을 높이는 단계입니다. 누락된 값은 제거하거나 평균/중앙값 대치, 예측 모델 대치 등의 <strong>결측치 처리</strong> 기법으로 다룰 수 있습니다<a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=or%20analysis,to%20handle%20missing%20values%20effectively">[2]</a><a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=imputer%20%3D%20SimpleImputer%28strategy%3D%27mean%27%29%20%20,column_with_missing">[3]</a>. 또한 <strong>이상치</strong>(outlier)를 탐지하여 제거하거나 영향 완화하고, 데이터 간 <strong>중복 레코드</strong>를 식별해 제거함으로써 데이터의 정확도를 높입니다<a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=It%20Handles%20Missing%20Data">[4]</a><a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=It%20Eliminates%20Duplicate%20Records">[5]</a>. 이와 함께, 여러 출처에서 온 데이터를 통합하고 형식을 변환(예: 범주형 변수를 원-핫 인코딩)하거나 <strong>정규화/스케일링</strong>하여 변수 스케일을 맞추는 등 모델 학습에 적합한 형태로 데이터를 변환합니다<a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=For%20example%3A">[6]</a><a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=,hot%20or%20label%20encoding%20techniques">[7]</a>. 이러한 정제 과정을 통해 <strong>데이터 품질 향상</strong> 및 <strong>쓰레기 입력 방지(Garbage in, garbage out)</strong> 효과를 얻어 <strong>모델 성능을 향상</strong>시킬 수 있습니다<a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=What%20is%20Data%20Preprocessing%20in,Machine%20Learning">[8]</a><a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=Data,into%20your%20machine%20learning%20algorithms">[9]</a>.</li>
<li><strong>데이터 증강:</strong> <strong>Data Augmentation</strong>은 <em>기존 데이터로부터 인위적으로 새로운 데이터를 생성</em>하여 데이터셋의 크기와 다양성을 늘리는 기법입니다<a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=Data%20augmentation">[10]</a>. 특히 <strong>딥러닝</strong> 모델에서는 대량의 훈련 데이터가 성능 향상에 중요하므로, 이미지나 텍스트 등의 분야에서 많이 활용됩니다. 예를 들어 이미지의 경우 <strong>회전, 반전, 크기변환, 잡음 추가</strong> 등의 변형을 통해 원본 이미지를 다양하게 바꿔 모델이 다양한 패턴을 학습하도록 합니다<a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=Data%20augmentation%20is%20a%20technique,required%20for%20robust%20model%20performance">[11]</a>. 자연어 텍스트의 경우 <strong>동의어 치환</strong>이나 <strong>역번역(back-translation)</strong> 등을 통해 문장을 변형하여 데이터를 증강할 수 있습니다<a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=target_size%3D">[12]</a><a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=aug%20%3D%20naw,a%20sample%20text%20for%20augmentation">[13]</a>. 이러한 증강 기법은 <strong>오버피팅을 방지</strong>하고 모델의 <strong>일반화 성능을 개선</strong>하는 데 효과적입니다.</li>
</ul>
<h2 id="ai-">AI 모델 개발</h2>
<ul>
<li><strong>아키텍처 설계:</strong> 문제에 적합한 <strong>AI 모델 구조를 설계</strong>하는 것은 핵심 개발 과제입니다. 현대 딥러닝에서는 <strong>합성곱 신경망(CNN)</strong>, <strong>순환 신경망(RNN)</strong>, <strong>트랜스포머(Transformer)</strong> 등 <strong>다양한 아키텍처 유형</strong>이 존재하며, 데이터 형태와 문제 특성에 따라 적절한 구조를 선택하거나 새로 설계해야 합니다. 예를 들어 <strong>트랜스포머</strong>는 자기어텐션(self-attention) 메커니즘을 통해 <strong>순차 데이터</strong>를 병렬로 처리함으로써 전통적 RNN의 한계를 넘어 <strong>NLP 작업의 효율과 성능을 혁신</strong>하였고<a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=The%20transformer%20architecture%2C%20introduced%20by,The%C2%A0transformer%20is%20described%C2%A0by">[14]</a>, <strong>ResNet</strong>은 층 간 출력에 <strong>직접 연결(skip connection)</strong>을 추가하는 <strong>잔차 학습</strong>으로 <strong>기존의 매우 딥(deep)한 신경망에서도 학습이 가능</strong>하도록 만들어 컴퓨터 비전 분야의 정확도를 크게 끌어올렸습니다<a href="https://medium.com/@rohanmistry231/understanding-resnet-a-deep-dive-into-residual-neural-networks-6d8c8c227fd0#:~:text=Deep%20learning%20has%20revolutionized%20computer,the%20problem%20of%20vanishing%20gradients">[15]</a>. 이러한 혁신 덕분에 수백 층 규모의 딥러닝 모델도 효과적으로 학습되었고, 이후 <strong>DenseNet</strong>, <strong>EfficientNet</strong>, <strong>Vision Transformer</strong> 등 보다 깊거나 효율적인 네트워크들이 등장하여 다양한 분야에 최적화된 아키텍처 설계가 이루어지고 있습니다. 아키텍처 설계 시에는 모델 용량(capacity)과 복잡도를 <strong>데이터 양과 문제 난이도에 맞게 조절</strong>하고, <strong>과적합 방지</strong>를 위한 규제 기법(Batch Norm, Dropout 등)도 함께 고려합니다. 최근에는 <strong>신경망 아키텍처 검색(NAS)</strong>이나 <strong>AutoML</strong> 기법을 통해 알고리즘이 자동으로 최적 아키텍처를 탐색하도록 하는 시도도 활발합니다.</li>
<li><strong>설명 가능한 AI (XAI):</strong> <strong>블랙박스</strong>로 여겨지는 복잡한 AI 모델의 <strong>의사결정 근거를 인간이 이해할 수 있도록 설명</strong>하려는 기술 및 방법론입니다. 딥러닝 모델이 높은 예측 성능을 보여도, 내부 결정 로직이 불투명하면 실제 현업 적용에서 <strong>신뢰성과 책임성</strong> 문제가 생기므로, XAI 분야의 연구가 2018년 이후 활발해졌습니다<a href="https://theaisummer.com/xai/#:~:text=To%20tackle%20the%20aforementioned%20issues%2C,in%20the%20machine%20learning%20community">[16]</a>. <strong>국지적 기법</strong>으로는 특정 예측에 가장 영향을 준 입력 특징을 추정하는 <strong>LIME</strong>이나 <strong>SHAP</strong> 같은 방법이 널리 쓰이고, <strong>전역 기법</strong>으로는 트리 모델의 <strong>결정경로 시각화</strong>나 신경망 가중치 규제 등을 통해 전체 구조의 해석력을 높이는 연구가 있습니다. 특히 딥러닝 비전 모델에서는 <strong>Class Activation Map</strong>이나 <strong>Grad-CAM</strong>처럼 최종 예측에 기여한 픽셀 영역을 <strong>하이라이트</strong>하여 보여주는 <strong>시각적 설명 기법</strong>이 개발되어 이미지 분류 결과를 설명하는 데 사용됩니다<a href="https://theaisummer.com/xai/#:~:text=information%20about%20the%20model%E2%80%99s%20decision">[17]</a>. 이외에도 <strong>대시보드 형태의 설명 보고</strong>(예: 특성 중요도 막대그래프, 부분의존도 그림)나 <strong>대안 시나리오 제시</strong>(counterfactual explanations) 등 다양한 XAI 접근법들이 존재합니다. XAI 기술을 활용하면 모델 사용자가 결과를 신뢰하고 모델의 오류 사례를 분석할 수 있으며, 금융이나 의료처럼 <strong>설명 요구</strong>가 높은 분야에서 <strong>규제 준수</strong>를 만족하면서 AI를 활용할 수 있게 됩니다<a href="https://theaisummer.com/xai/#:~:text=Deep%20learning%20applications%20have%20drawn,applications%20lack%20explainability%20and%20reliability">[18]</a><a href="https://theaisummer.com/xai/#:~:text=To%20tackle%20the%20aforementioned%20issues%2C,in%20the%20machine%20learning%20community">[16]</a>.</li>
<li><strong>모델 학습 및 평가:</strong> <strong>모델 학습</strong> 단계에서는 주어진 훈련 데이터에 대해 최적화 알고리즘(예: SGD, Adam 등)을 사용해 모델 파라미터를 갱신하며, 동시에 <strong>검증 데이터</strong>를 통해 일반화 성능을 점검합니다. 이때 <strong>학습曲선(Learning Curve)</strong>을 모니터링하여 <strong>과적합</strong>(overfitting)이나 <strong>과소적합</strong>(underfitting) 여부를 진단하는 것이 중요합니다<a href="https://medium.com/data-science/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5#:~:text=Learning%20curves%20are%20an%20efficient,may%20fail%20to%20identify%20them">[19]</a><a href="https://medium.com/@aarishalam22/understanding-overfitting-underfitting-and-learning-curves-in-machine-learning-fe19825125c8#:~:text=Understanding%20Overfitting%2C%20Underfitting%2C%20and%20Learning,indicate%20underfitting%2C%20increase%20model">[20]</a>. 예를 들어 <strong>과적합</strong>이라면 <strong>훈련 손실</strong>은 계속 감소하여 거의 0에 가깝게 낮아지지만, <strong>검증 손실</strong>은 어느 시점 이후 더 이상 감소하지 않다가 오히려 증가세로 돌아서게 됩니다<a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=For%20an%20overfit%20model%2C%20the,on%20unseen%20data%20is%20deteriorating">[21]</a>. 이때 훈련/검증 손실 곡선 사이에 <strong>큰 격차</strong>가 나타나며, 이는 모델이 학습 데이터의 패턴뿐 아니라 <strong>노이즈까지 암기</strong>하여 새로운 데이터에 성능이 떨어지는 전형적인 징후입니다<a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=the%20validation%20loss%20stops%20decreasing,on%20unseen%20data%20is%20deteriorating">[22]</a><a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=A%20significant%20gap%20between%20the,worse%20on%20the%20validation%20set">[23]</a>. 반대로 <strong>과소적합</strong> 상태에서는 <strong>훈련 손실</strong> 자체가 높게 남아 있고 검증 손실도 비슷하게 높은 수준을 유지하여, 두 곡선 사이 <strong>격차는 크지 않지만 전반적으로 오류율이 높게</strong> 나타납니다<a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=,on%20unseen%20data%20as%20well">[24]</a>. 이 경우 모델 복잡도를 높이거나 더 많은 특징을 학습하도록 개선해야 합니다. 모델 평가 단계에서는 <strong>평가 지표</strong>를 사용해 성능을 정량적으로 측정합니다. 분류 문제에서는 <strong>정확도(Accuracy)</strong> 외에도 <strong>정밀도(Precision)</strong>, <strong>재현율(Recall)</strong>, <strong>F1-점수</strong> 등의 지표를 활용합니다. 특히 데이터 <strong>클래스 불균형</strong>이 심한 경우 단순 정확도는 착시를 줄 수 있어(예: 99%가 정상이고 1%가 이상치인 데이터에서 무조건 정상으로 예측하면 99% 정확도)<a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=While%20accuracy%20is%20often%20the,For%20example">[25]</a>, 실제 긍정 예측 중 얼마나 실제 긍정인가를 보는 <strong>정밀도</strong>, 실제 긍정 샘플 중 놓치지 않고 잡아낸 비율인 <strong>재현율</strong>, 두 값의 조화평균인 <strong>F1</strong> 등의 지표가 더욱 <strong>유용한 통찰</strong>을 제공합니다<a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=In%20the%20world%20of%20machine,learn.%20Let%E2%80%99s%20dive%20in">[26]</a><a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=While%20accuracy%20is%20often%20the,For%20example">[25]</a>. 예컨대 <strong>스팸 필터링</strong>에서는 중요한 메일이 스팸으로 잘못 차단되지 않도록 <strong>정밀도</strong>가 중요하고, <strong>암 환자 진단</strong> 모델에서는 환자를 놓치지 않는 <strong>재현율</strong>이 중요하듯이, 문제 성격에 따라 적절한 평가 척도를 선택해야 합니다<a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=,classifying%20important%20emails%20as%20spam">[27]</a><a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=,off">[28]</a>. 회귀 문제에서는 <strong>평균제곱오차(MSE)</strong>, <strong>평균절대오차(MAE)</strong>, <strong>R² 점수</strong> 등이 활용되며, 랭킹/검색 문제에서는 <strong>AUC</strong>(곡선하면적)나 <strong>MAP</strong> 등이 쓰입니다. 다양한 지표를 종합적으로 고려해 모델을 평가함으로써 모델의 강점과 약점을 파악하고 향후 개선 방향을 도출할 수 있습니다.</li>
<li><strong>모델 튜닝 기법:</strong> 최적의 모델 성능을 얻기 위해 <strong>하이퍼파라미터 최적화(Hyperparameter Optimization, HPO)</strong>와 <strong>불균형 데이터 처리</strong> 등의 튜닝 기법을 적용합니다.</li>
<li><em>하이퍼파라미터 최적화:</em> 학습률, 은닉층 크기, 정규화 계수 등 모델의 하이퍼파라미터를 체계적으로 탐색하여 최적 조합을 찾는 과정입니다. <strong>그리드 탐색(Grid Search)</strong>과 <strong>랜덤 탐색(Random Search)</strong>이 전통적으로 가장 많이 사용되는 접근법이며, 전자는 미리 정한 모든 조합을 전수 평가하고 후자는 설정한 횟수만큼 무작위 조합을 평가합니다<a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=The%20two%20most%20common%20approaches,for%20hyperparameter%20tuning%20are">[29]</a>. 다만 그리드/랜덤 탐색은 <strong>탐색 범위</strong>에 포함된 값들만 평가하고 <strong>연속 변수도 이산 샘플링</strong>하므로 비효율적일 수 있습니다<a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=,This%20is%20computationally%20expensive">[30]</a><a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=,if%20the%20hyperparameter%20is%20continuous">[31]</a>. 최근에는 <strong>베이지안 최적화</strong>가 <strong>보다 적은 시도로 우수한 하이퍼파라미터를 찾는</strong> 강력한 방법으로 각광받고 있습니다<a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=To%20this%20end%2C%20Bayesian%20Optimization,powerful%20approach%20for%20tuning%20hyperparameters">[32]</a>. 베이지안 방법은 이전 시도들의 평가 결과를 바탕으로 다음 실험 지점을 <strong>똑똑하게 선택</strong>하여, 불필요한 영역을 배제하고 <strong>더 빠르게 수렴</strong>합니다<a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=Both%20Grid%20search%20and%20Random,find%20the%20most%20optimal%20one">[33]</a><a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=The%20efficacy%20of%20Bayesian%20Optimization,evident%20from%20the%20image%20below">[34]</a>. 이외에도 <strong>진화 알고리즘</strong>, <strong>Hyperband</strong> 등의 기법과 Optuna, Ray Tune 같은 HPO 프레임워크를 활용하여 효율적으로 모델 튜닝을 수행합니다.</li>
<li><em>클래스 불균형 해결:</em> 현실 데이터셋에서는 특정 클래스가 매우 드문 경우가 많아(Model의 편향 초래) 이를 보정해줘야 합니다. <strong>데이터 수준 방법</strong>으로는 <strong>오버샘플링</strong>과 <strong>언더샘플링</strong>이 기본적입니다. 오버샘플링은 <strong>소수 클래스 데이터를 복제</strong>하거나 <strong>합성하여(SMOTE 등)</strong> 데이터 비율을 높이는 방법이고<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=3">[35]</a>, 언더샘플링은 다수 클래스 데이터 중 일부를 제거하여 균형을 맞추는 기법입니다<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=,Samples">[36]</a>. 예를 들어 imblearn 라이브러리의 RandomOverSampler나 SMOTE를 이용해 소수 클래스 샘플을 증가시킬 수 있습니다<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=,examples%20to%20balance%20the%20dataset">[37]</a><a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=SMOTE%20%28Synthetic%20Minority%20Over,nearest%20neighbors">[38]</a>. <strong>알고리즘 수준 방법</strong>으로는 <strong>비용 민감 학습</strong>이 있습니다. 이는 모델 학습 시 <strong>클래스별 가중치</strong>를 달리 부여해, 희소한 클래스의 오류에 더 큰 페널티를 주는 방식입니다<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Instead%20of%20modifying%20the%20dataset%2C,misclassifications%20of%20the%20minority%20class">[39]</a>. 사이킷런의 class_weight=&#39;balanced&#39; 옵션이나 XGBoost의 scale_pos_weight 파라미터 등이 이러한 역할을 합니다<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Python%20Example%20%28Scikit">[40]</a><a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Python%20Example%3A">[41]</a>. 더 나아가 <strong>Focal Loss</strong>처럼 <strong>어려운 예제에 가중치를 더 부여</strong>하는 특수 손실함수도 많이 쓰입니다<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Focal%20Loss%20for%20Handling%20Class,Imbalance">[42]</a>. Focal Loss는 분류기가 쉽게 맞히는 다수 클래스 샘플에서는 손실 기여도를 낮추고, 소수 클래스처럼 오분류하기 쉬운 샘플에 더 큰 가중 손실을 부여함으로써 <strong>불균형 데이터를 효과적으로 학습</strong>하도록 설계된 기법입니다<a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Focal%20Loss%20for%20Handling%20Class,Imbalance">[42]</a>. 이러한 튜닝 기법을 통해 <strong>데이터 불균형으로 인한 성능 저하</strong>나 <strong>하이퍼파라미터 부적절 설정으로 인한 미최적화</strong>를 방지하고, 모델의 성능을 극대화할 수 있습니다.</li>
</ul>
<h2 id="ai-">AI 시스템 구축</h2>
<ul>
<li><strong>ML 파이프라인 설계 및 배포:</strong> 데이터 수집부터 모델 배포까지의 과정을 <strong>자동화된 파이프라인</strong>으로 구성하는 것이 중요합니다. 일반적인 ML 파이프라인은 데이터 수집/전처리 → 모델 학습 → 모델 검증 → 배포의 단계를 거치며, 이를 효율적으로 운영하기 위해 <strong>MLOps</strong> 개념이 등장했습니다. MLOps는 소프트웨어 개발의 <strong>DevOps</strong> 원칙을 머신러닝에 접목한 것으로, <strong>CI/CD(지속적 통합/전달)</strong> 뿐 아니라 <strong>CT(지속적 학습)</strong>를 통해 모델을 지속적으로 개선/배포하는 전략입니다<a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=This%20document%20discusses%20techniques%20for,primarily%20to%20predictive%20AI%20systems">[43]</a><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=This%20document%20is%20for%20data,releasing%2C%20deployment%20and%20infrastructure%20management">[44]</a>. <strong>Google</strong> 등에 따르면 <em>“MLOps 실천이란 통합, 테스트, 릴리즈, 배포, 인프라 관리 등</em> <em>ML 시스템 구축의 모든 단계에 자동화와 모니터링을 적용하는 것”</em>이라고 정의됩니다<a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=culture%20and%20practice%20that%20aims,releasing%2C%20deployment%20and%20infrastructure%20management">[45]</a>. 이를 구현하기 위해 <strong>파이프라인 오케스트레이션 도구</strong>(Kubeflow, Airflow 등)를 사용해 <strong>데이터 준비, 학습, 평가, 배포 단계</strong>를 연결하고, <strong>컨테이너화</strong> 및 <strong>인프라스 코드(IaC)</strong>로 일관된 환경에서 재현성을 확보합니다. 또한 모델을 <strong>REST API나 Microservice</strong>로 패키징하여 클라우드나 엣지 서버에 배포하고, AB 테스트나 점진적 롤아웃을 통해 안정적으로 사용자 트래픽에 노출합니다<a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Serving%20architecture">[46]</a><a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Image%3A%20Online%2Freal">[47]</a>. <strong>Feature Store</strong>를 구축해 온라인/오프라인 특성 일관성을 관리하거나, <strong>모델 버전관리</strong>를 통해 이전 모델과 성능을 비교하며, <strong>데이터 및 모델에 대한 형상관리(DVC, Model Registry)</strong>도 적용합니다. 이러한 체계적인 파이프라인 설계는 모델 개발부터 서비스 배포까지의 사이클을 단축하고, <strong>지속적인 업데이트</strong>를 가능케 하여 비즈니스 가치를 신속히 제공합니다<a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=This%20document%20is%20for%20data,releasing%2C%20deployment%20and%20infrastructure%20management">[44]</a><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=However%2C%20the%20real%20challenge%20isn%27t,Credit%20Card%20of%20Technical%20Debt">[48]</a>.</li>
<li><strong>AI 시스템 모니터링 및 자동화:</strong> 모델이 운영 환경에 배포된 이후에는 <strong>지속적인 모니터링</strong>을 통해 성능 저하나 데이터 이상을 감지하고 자동으로 대응하는 것이 중요합니다. <strong>모델 모니터링</strong> 측면에서, <strong>예측 성능 지표</strong>(정확도, 응답시간 등)를 <strong>실시간으로 추적</strong>하여 임계치 미달 시 경고를 발생시키거나 <strong>재학습 트리거</strong>를 거는 체계를 갖춥니다. 특히 입력 데이터 분포나 관계가 훈련 시와 달라지는 <strong>드리프트(drift)</strong>를 탐지하는 것이 핵심입니다. <strong>데이터 드리프트</strong>는 입력 특성들의 분포 변화(예: 이미지 밝기나 텍스트 어휘의 변화)이고, <strong>개념 드리프트</strong>는 입력과 출력 간의 관계 변화(예: 소비자 행동 패턴 변화로 모델이 학습한 관계가 무효화됨)를 의미합니다<a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/#:~:text=Concept%20drift%20refers%20to%20that,replaced%20with%20a%20new%20set">[49]</a>. <strong>개념 드리프트</strong> 발생 시에는 기존 모델이 더 이상 올바른 예측을 못하게 되므로 <strong>훈련 데이터 갱신 및 모델 재학습</strong>이 필요합니다<a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/#:~:text=Concept%20drift%20refers%20to%20that,replaced%20with%20a%20new%20set">[49]</a>. 한편 <strong>데이터 드리프트</strong>는 개념 드리프트의 <strong>전조 현상</strong>으로 볼 수 있어, 입력 데이터 분포가 유의미하게 달라지는 조짐을 조기에 포착하면 본격적인 성능 저하 전에 <strong>선제적으로 대응(모델 재훈련 등)</strong>할 수 있습니다<a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/#:~:text=your%20model,significant%20prediction%20drift%20sets%20in">[50]</a>. 예를 들어 <strong>모니터링 도구</strong>를 통해 모델 입력 데이터의 통계량(KL 다이버전스 등으로 측정)을 지속 추적하고, 일정 임계치를 넘으면 자동으로 <strong>새 데이터로 모델을 재훈련</strong>하는 파이프라인을 가동합니다<a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/#:~:text=your%20model,significant%20prediction%20drift%20sets%20in">[50]</a>. 이외에도 시스템 모니터링 측면에서 <strong>서버 리소스 사용률(GPU/메모리)</strong>, <strong>처리량(QPS)</strong>, <strong>에러 율</strong> 등을 추적하여 <strong>운영 안정성</strong>을 유지합니다. <strong>자동화</strong> 측면에서는 정기적으로 파이프라인이 동작하도록 <strong>스케줄러</strong>를 설정하고, 새로운 데이터 발생 시 <strong>이벤트 트리거 방식</strong>으로 실시간 학습/배포가 일어나게 할 수 있습니다<a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=You%20may%20need%20this%20if,stream%20analytics%20or%20online%20serving">[51]</a><a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Image%3A%20Message,Source%3A%20author">[52]</a>. 나아가 <strong>모델 성능 저하 감지 → 데이터 큐레이션 → 재학습 → 배포</strong>까지 완전히 자동화된 <strong>피드백 루프</strong>를 구축하면, 사람이 개입하지 않아도 AI 시스템이 <strong>자체적으로 진화</strong>하고 문제를 수정해나갈 수 있습니다<a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Essentially%2C%20it%20joins%20the%20data,time%20transactions%20%28fraud%20detection%20applications">[53]</a><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=Data%20scientists%20can%20implement%20and,Credit%20Card%20of%20Technical%20Debt">[54]</a>. 이러한 모니터링 및 자동화는 <strong>모델의 신뢰성</strong>과 <strong>서비스 수준 목표(SLO)</strong>를 유지하는 데 필수적입니다.</li>
<li><strong>AI 시스템 최적화:</strong> AI 모델을 실제 서비스에 활용하려면 <strong>응답 지연 최소화</strong>, <strong>처리량 향상</strong>, <strong>인프라 비용 절감</strong> 등을 위한 최적화가 요구됩니다. <strong>모델 경량화</strong>는 대표적인 최적화 기법으로, 불필요한 복잡도를 줄여 <strong>추론 속도</strong>를 높이고 <strong>메모리 사용량</strong>을 줄입니다. 예를 들어 <strong>모델 가지치기(pruning)</strong>는 중요도가 낮은 뉴런이나 가중치를 제거하여 모델 크기를 줄이고 계산량을 감소시킵니다. <strong>양자화(quantization)</strong> 기법은 모델 가중치와 연산을 32비트 부동소수 대신 16비트나 8비트 정밀도로 표현하여 <strong>메모리 사용량과 연산량을 크게 줄이는</strong> 방법입니다<a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=Optimization%20techniques%20like%20pruning%2C%20quantization%2C,vital%20for%20improving%20computational%20efficiency">[55]</a>. 또한 <strong>지식 증류(Knowledge Distillation)</strong>는 복잡한 <strong>대형 모델(교사)</strong>의 지식을 <strong>경량 모델(학생)</strong>에 옮겨서, 성능은 유지하면서도 훨씬 <strong>작고 빠른 모델</strong>을 얻는 최적화 전략입니다<a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=Optimization%20techniques%20like%20pruning%2C%20quantization%2C,vital%20for%20improving%20computational%20efficiency">[55]</a>. 이러한 모델 수준 최적화 외에도, <strong>병렬 분산 처리</strong>와 <strong>하드웨어 가속</strong>을 통해 시스템을 최적화합니다. 예를 들어 <strong>멀티스레딩</strong>이나 <strong>멀티-GPU 분산 추론</strong>으로 일처리량을 높이고, CUDA/TensorRT와 같은 <strong>최적화 라이브러리</strong>를 활용하여 하드웨어의 최대 성능을 끌어냅니다. <strong>배치 처리 크기</strong>를 조절하거나 <strong>동적 연산 그래프 최적화</strong>(런타임 최적화)로 지연 시간을 단축할 수도 있습니다. 이밖에 <strong>캐싱</strong>을 통해 동일한 입력에 대한 반복 연산을 줄이고, <strong>메모리 최적화 기법</strong>으로 CPU-GPU 간 전송 병목을 줄이는 등 시스템 전반에 걸친 튜닝을 실시합니다. 마지막으로 이러한 최적화의 효과와 트레이드오프(예: 양자화로 인한 미세 성능 감소)를 <strong>평가 지표</strong>로 모니터링하면서 최적의 균형점을 찾아 적용합니다<a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=,performance%20with%20less%20computational%20demand">[56]</a><a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=In%20this%20article%2C%20I%E2%80%99ll%20review,apply%20them%20in%20your%20projects">[57]</a>. 결과적으로 AI 시스템 최적화를 통해 <strong>실시간 서비스</strong>에서 요구하는 성능을 만족하고, <strong>비용 효율적</strong>으로 모델을 운영할 수 있게 됩니다.</li>
</ul>
<h2 id="-ai-2018-">주요 AI 기술 트렌드 (2018년~현재)</h2>
<ul>
<li><strong>트랜스포머와 초거대 언어모델:</strong> 2017년 말 등장한 <strong>트랜스포머(Transformer)</strong> 아키텍처는 이후 NLP 분야를 지배하는 표준이 되었습니다. 트랜스포머는 <strong>자기어텐션 메커니즘</strong>을 통해 RNN 없이도 문장 내 장거리 의존성을 효과적으로 포착하며 병렬 연산이 가능해, <strong>번역, 질의응답, 요약</strong> 등 NLP 성능을 혁신적으로 향상시켰습니다<a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=The%20transformer%20architecture%2C%20introduced%20by,The%C2%A0transformer%20is%20described%C2%A0by">[14]</a>. 2018년 등장한 <strong>BERT</strong>는 트랜스포머를 <strong>양방향(bidirectional)</strong>으로 학습하여 문맥 이해 능력을 끌어올렸고, 2020년 발표된 <strong>GPT-3</strong>는 <strong>1750억 개</strong>에 이르는 파라미터를 가진 초대규모 <strong>사전학습 언어모델</strong>로서 인간에 가까운 자연어 생성 능력을 보여주었습니다<a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=BERT%E2%80%99s%20bidirectional%20training%20of%20transformers,162%5D.%20Their">[58]</a>. 이러한 <strong>거대 언어모델(LLM)</strong>의 계보는 곧 <strong>GPT-4</strong> 등으로 이어졌고, 2022년 말 공개된 OpenAI의 <strong>ChatGPT</strong>는 일반 대중에게도 <strong>생성형 AI</strong>의 강력함을 인식시킨 사건으로 평가됩니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=2022%EB%85%84%207%EC%9B%94%2C%20Open%20AI%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C,%EA%B7%B8%EB%9F%B0%20%EB%8B%A4%EC%9D%8C%20ChatGPT%EA%B0%80%20%EC%99%94%EC%8A%B5%EB%8B%88%EB%8B%A4">[59]</a>. 현재 LLM들은 <strong>소규모 감독</strong> 또는 <strong>미세조정(fine-tuning)</strong>만으로도 새로운 NLP 태스크에 높은 성능을 보이며, 지식 검색, 코딩 보조, 대화형 에이전트 등 <strong>산업 전반에 변혁</strong>을 일으키고 있습니다. 또한 트랜스포머 구조는 <strong>비전</strong>(Vision Transformer, 2020)과 <strong>음성</strong> 등 다른 도메인에도 응용되어 <strong>범용 모델 아키텍처</strong>로 자리잡고 있습니다<a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=Transformers%20have%20significantly%20impacted%20several,has%20demonstrated%20the%20transformer%E2%80%99s%20impact">[60]</a>.</li>
<li><strong>생성형 AI의 부상:</strong> 2014년 <strong>GAN</strong>(생성적 적대 신경망)의 발명 이후로 AI가 새로운 데이터를 창조해내는 <strong>생성형 모델</strong> 연구가 급성장했습니다. 이미지 생성, 동영상 생성, 텍스트 생성 등 다양한 분야에서 생성 모델들이 등장했으며, 2018~2019년에는 <strong>GAN</strong> 기반으로 놀랍도록 현실적인 <strong>딥페이크</strong> 영상과 사진이 화제가 되기도 했습니다. 2022년에는 OpenAI의 <strong>DALL-E 2</strong>가 문자 설명만으로도 고해상도 이미지를 만들어내어 전세계적인 관심을 모았고, 뒤이어 공개된 <strong>Stable Diffusion</strong> 등 <strong>확산 모델(Diffusion Model)</strong> 기반 생성기도 예술, 디자인 분야에 큰 반향을 일으켰습니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EC%83%9D%EC%84%B1%20AI%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%80%20%EA%B8%B0%EC%A1%B4%20%EB%8D%B0%EC%9D%B4%ED%84%B0,%EC%97%86%EB%8A%94%20%EC%99%84%EC%A0%84%ED%9E%88%20%EC%83%88%EB%A1%9C%EC%9A%B4%20%EC%BD%98%ED%85%90%EC%B8%A0%EB%A5%BC%20%EC%83%9D%EC%84%B1%ED%95%A9%EB%8B%88%EB%8B%A4">[61]</a><a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=2022%EB%85%84%207%EC%9B%94%2C%20Open%20AI%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C,%EA%B7%B8%EB%9F%B0%20%EB%8B%A4%EC%9D%8C%20ChatGPT%EA%B0%80%20%EC%99%94%EC%8A%B5%EB%8B%88%EB%8B%A4">[62]</a>. 한편 텍스트 생성에서는 앞서 언급한 GPT 계열 모델이 주도하여, <strong>블로그 글</strong>, <strong>시나리오</strong>, <strong>프로그램 코드</strong>까지 자동 생성하는 <strong>자연어 생성</strong> 활용이 폭발적으로 늘었습니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EA%B0%80%EC%9E%A5%20%EC%9E%98%20%EC%95%8C%EB%A0%A4%EC%A7%84%20%EC%83%9D%EC%84%B1%20AI,%EB%B3%80%EC%A2%85%EC%9D%80%20%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%A5%BC%20%EC%83%9D%EC%84%B1%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%82%AC%EC%9A%A9%EB%90%A9%EB%8B%88%EB%8B%A4">[63]</a>. 이러한 생성형 AI 기술은 <strong>콘텐츠 생산성</strong>을 높이고 새로운 <strong>비즈니스 기회</strong>를 창출하지만, 한편으로 <strong>허위정보 생성</strong>이나 <strong>저작권</strong> 이슈 등의 윤리적 문제도 대두되어 이에 대한 대응 연구도 활발합니다. 그럼에도 생성형 AI는 <strong>2020년대 핵심 기술 트렌드</strong>로 자리매김했으며, 이미지-텍스트 간 상호생성, 멀티모달 생성(텍스트→영상, 텍스트→3D 모델 등)처럼 다양한 형태로 진화하고 있습니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=LLM%EC%9D%80%20%EA%B5%90%EC%9C%A1%20%EA%B0%90%EB%8F%85%EC%9D%B4%20%EA%B1%B0%EC%9D%98%20%EB%98%90%EB%8A%94,%EC%83%9D%EC%84%B1%ED%95%A0%20%EC%88%98%20%EC%9E%88%EB%8A%94%20%ED%95%99%EC%8A%B5%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9E%85%EB%8B%88%EB%8B%A4">[64]</a><a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EA%B3%A0%EA%B0%9D%EC%9D%98%20%EC%A7%88%EB%AC%B8%EC%97%90%20%EB%8B%B5%ED%95%98%EA%B1%B0%EB%82%98%20%EB%AC%B8%EC%9E%90%2C%20%EC%86%8C%EB%A6%AC%2C,%ED%8F%AC%ED%95%A8%ED%95%98%EB%8A%94%20%EB%8B%A4%EC%96%91%ED%95%9C%20%EC%96%91%EC%8B%9D%EC%9D%B4%20%EC%A6%9D%EA%B0%80%ED%95%98%EA%B3%A0%20%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4">[65]</a>.</li>
<li><strong>컴퓨터 비전 모델 혁신:</strong> <strong>이미지 인식</strong>을 비롯한 컴퓨터 비전 분야에서는 2012년 <strong>AlexNet</strong>을 시작으로 한 <strong>CNN 아키텍처</strong> 발전이 이어져왔고, 2015년 <strong>ResNet</strong>의 등장으로 <strong>초딥 신경망</strong>의 효과적인 학습이 가능해진 것이 큰 전환점이었습니다<a href="https://medium.com/@rohanmistry231/understanding-resnet-a-deep-dive-into-residual-neural-networks-6d8c8c227fd0#:~:text=Deep%20learning%20has%20revolutionized%20computer,the%20problem%20of%20vanishing%20gradients">[15]</a>. ResNet은 152층까지 누적된 매우 깊은 네트워크로 <strong>ImageNet 대회</strong>를 제패하며 사실상 CV 모델의 기본 구성이 되었고, 이후 <strong>ResNeXt</strong>, <strong>WideResNet</strong>, <strong>DenseNet</strong> 등 변종들이 나와 특성 추출 능력을 높였습니다. 2017년에는 <strong>셀프-어텐션</strong> 구조를 결합한 <strong>Non-local Neural Network</strong>가 비전에도 주목받았고, 2019년 구글의 <strong>EfficientNet</strong>은 <strong>네트워크 깊이·너비·해상도를 균형 있게 스케일업</strong>하는 <strong>Compound Scaling</strong>으로 <strong>적은 파라미터로도 높은 정확도</strong>를 달성하여 실용적인 모델 설계 방향을 제시했습니다<a href="https://viso.ai/deep-learning/efficientnet/#:~:text=EfficientNet%20is%20a%20Convolutional%20Neural,high%20accuracy%20with%20computational%20efficiency">[66]</a><a href="https://viso.ai/deep-learning/efficientnet/#:~:text=Increasing%20the%20complexity%20of%20CNNs,which%20demands%20more%20computational%20resources">[67]</a>. 2020년에는 NLP 혁신이었던 <strong>Transformer</strong>를 이미지 처리에 적용한 <strong>Vision Transformer(ViT)</strong>가 제안되어, 대규모 데이터에서 <strong>Conv 레이어 없이도 SOTA 수준 시각 인식</strong>이 가능함을 보였습니다<a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=Transformers%20have%20significantly%20impacted%20several,has%20demonstrated%20the%20transformer%E2%80%99s%20impact">[60]</a>. 이후 ViT를 개선한 <strong>SWIN Transformer</strong> 등 <strong>어텐션 기반 비전 모델</strong>들이 등장하며 <strong>CNN과 어텐션의 융합</strong>이 이루어지고 있습니다. 또한 <strong>자기지도 학습</strong>과 <strong>대량의 사전학습(backbone)</strong> 트렌드에 따라, <strong>CLIP</strong> 같은 거대 멀티모달 모델을 비전 분야에 활용하고 후속 작업에 파인튜닝하는 <strong>Transfer Learning</strong>이 표준화되었습니다. 요약하면, 컴퓨터 비전에서도 <strong>모델 아키텍처의 지속적 발전</strong>과 <strong>대규모 데이터/모델 활용</strong>이라는 두 축이 2018년 이후 현재까지 주요 트렌드입니다.</li>
<li><strong>연합학습(Federated Learning)과 프라이버시 강화:</strong> 데이터 <strong>프라이버시</strong>에 대한 관심이 높아지면서, 2017년경부터 제안된 <strong>연합학습</strong>이 실제 적용 단계로 접어들었습니다. 연합학습은 <strong>훈련 데이터를 중앙 서버에 모으지 않고</strong>도 각 기기에서 <strong>지역(local) 모델을 학습</strong>하고 이를 서버에서 합치는 방식으로 <strong>분산된 환경에서 공동 학습</strong>을 가능케 합니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,Federated%20learning">[68]</a>. 예를 들어 스마트폰 키보드의 단어 추천 모델을 위해 사용자의 입력 데이터를 서버로 보내지 않고 기기 내에서 학습시킨 뒤 모델 업데이트만 공유하는 식입니다. 이 방법은 개인정보 노출 위험을 줄이고, <strong>데이터가 분산된 상태에서도 글로벌 모델</strong>을 구축할 수 있다는 장점이 있어 <strong>모바일 AI 및 의료AI</strong> 분야에서 주목받고 있습니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,Federated%20learning">[68]</a>. 구글은 <strong>TensorFlow Federated</strong> 프레임워크를 공개했고, 다양한 기업에서 이를 활용한 <strong>프라이버시 보존 ML</strong>을 연구 중입니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EC%97%B0%ED%95%A9%20%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9D%BC%EB%8A%94%20%EC%9D%B8%EA%B3%B5%20%EC%A7%80%EB%8A%A5%EC%9D%98%20%EC%83%88%EB%A1%9C%EC%9A%B4,%EC%84%B1%EB%8A%A5%E2%80%9D%EC%9D%84%20%EB%AA%A8%EB%91%90%20%EC%82%AC%EC%9A%A9%ED%95%A0%20%EC%88%98%20%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4">[69]</a>. 한편 <strong>엣지 AI</strong> 역시 트렌드로, 센서가 달린 엣지 디바이스(카메라, IoT장치 등) 자체에서 <strong>경량화된 ML 추론</strong>을 수행하는 사례가 늘고 있습니다. Gartner 보고서에 따르면 <strong>AIoT</strong>라 불리는 AI+IoT 융합 영역에서, 2025년까지 기업 IoT 프로젝트의 80% 이상에 AI 기능이 포함될 것으로 전망됩니다<a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,AIoT">[70]</a>. 이는 곧 네트워크 지연이나 프라이버시 이슈 없이 <strong>현장에서 실시간 의사결정</strong>을 내리는 <strong>분산 AI 시스템</strong>의 시대가 오고 있음을 의미합니다. 이 밖에도 <strong>강화학습(RL)의 발전</strong>(알파스타, OpenAI Five 등), <strong>그래프 신경망(GNN)의 부상</strong>(소셜 네트워크 및 추천시스템 활용) 등도 2018년 이후 두드러진 흐름입니다. 전반적으로 <strong>대규모 사전학습 모델의 활용</strong>, <strong>멀티모달 통합</strong>, <strong>자동화된 ML파이프라인(MLOps)</strong>, <strong>프라이버시 및 윤리적 AI</strong>가 현재 AI 분야의 화두이며, 기업들은 이러한 기술 트렌드를 빠르게 업무에 도입해 <strong>서비스 혁신</strong>과 <strong>경쟁력 강화</strong>를 도모하고 있습니다<a href="https://careerly.co.kr/comments/75278#:~:text=MLOps%202023%EB%85%84%EC%9D%98%20%EB%AA%87%20%EA%B0%80%EC%A7%80%20%EC%A3%BC%EC%9A%94,%EB%A7%8E%EC%9D%80%20%EB%8F%84%EC%9B%80%EC%9D%B4%20%EB%90%A0%20%EA%B1%B0%EB%9D%BC%20%EB%AF%BF%EC%8A%B5%EB%8B%88%EB%8B%A4">[71]</a><a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,MLOps">[72]</a>.</li>
</ul>
<p><a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=This%20is%20why%20data%20preprocessing,to%20data%20preprocessing%20and%20management">[1]</a> <a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=It%20Handles%20Missing%20Data">[4]</a> <a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=It%20Eliminates%20Duplicate%20Records">[5]</a> <a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=What%20is%20Data%20Preprocessing%20in,Machine%20Learning">[8]</a> <a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/#:~:text=Data,into%20your%20machine%20learning%20algorithms">[9]</a> Data Preprocessing in Machine Learning: Steps &amp; Best Practices</p>
<p><a href="https://lakefs.io/blog/data-preprocessing-in-machine-learning/">https://lakefs.io/blog/data-preprocessing-in-machine-learning/</a></p>
<p><a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=or%20analysis,to%20handle%20missing%20values%20effectively">[2]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=imputer%20%3D%20SimpleImputer%28strategy%3D%27mean%27%29%20%20,column_with_missing">[3]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=For%20example%3A">[6]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=,hot%20or%20label%20encoding%20techniques">[7]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=Data%20augmentation">[10]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=Data%20augmentation%20is%20a%20technique,required%20for%20robust%20model%20performance">[11]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=target_size%3D">[12]</a> <a href="https://www.datacamp.com/blog/data-preprocessing#:~:text=aug%20%3D%20naw,a%20sample%20text%20for%20augmentation">[13]</a> Data Preprocessing: A Complete Guide with Python Examples | DataCamp</p>
<p><a href="https://www.datacamp.com/blog/data-preprocessing">https://www.datacamp.com/blog/data-preprocessing</a></p>
<p><a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=The%20transformer%20architecture%2C%20introduced%20by,The%C2%A0transformer%20is%20described%C2%A0by">[14]</a> <a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=BERT%E2%80%99s%20bidirectional%20training%20of%20transformers,162%5D.%20Their">[58]</a> <a href="https://www.mdpi.com/2078-2489/15/12/755#:~:text=Transformers%20have%20significantly%20impacted%20several,has%20demonstrated%20the%20transformer%E2%80%99s%20impact">[60]</a> A Comprehensive Review of Deep Learning: Architectures, Recent Advances, and Applications</p>
<p><a href="https://www.mdpi.com/2078-2489/15/12/755">https://www.mdpi.com/2078-2489/15/12/755</a></p>
<p><a href="https://medium.com/@rohanmistry231/understanding-resnet-a-deep-dive-into-residual-neural-networks-6d8c8c227fd0#:~:text=Deep%20learning%20has%20revolutionized%20computer,the%20problem%20of%20vanishing%20gradients">[15]</a> Understanding ResNet: A Deep Dive into Residual Neural Networks | by Rohan Mistry | Medium</p>
<p><a href="&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#x3a;&#x68;&#x74;&#x74;&#112;&#115;&#58;&#x2f;&#47;&#x6d;&#101;&#100;&#105;&#117;&#x6d;&#x2e;&#99;&#x6f;&#109;&#x2f;&#x40;&#x72;&#x6f;&#104;&#x61;&#x6e;&#x6d;&#105;&#x73;&#116;&#x72;&#x79;&#x32;&#x33;&#49;&#x2f;&#117;&#x6e;&#100;&#x65;&#114;&#115;&#116;&#97;&#110;&#100;&#105;&#x6e;&#103;&#45;&#114;&#x65;&#115;&#110;&#x65;&#116;&#45;&#x61;&#45;&#x64;&#101;&#x65;&#x70;&#x2d;&#x64;&#105;&#118;&#x65;&#45;&#x69;&#x6e;&#x74;&#111;&#45;&#114;&#x65;&#x73;&#x69;&#100;&#x75;&#97;&#x6c;&#45;&#110;&#x65;&#117;&#114;&#97;&#108;&#45;&#x6e;&#101;&#x74;&#119;&#111;&#x72;&#107;&#115;&#x2d;&#x36;&#x64;&#x38;&#99;&#56;&#x63;&#x32;&#50;&#55;&#102;&#100;&#48;">&#x68;&#x74;&#x74;&#112;&#115;&#58;&#x2f;&#47;&#x6d;&#101;&#100;&#105;&#117;&#x6d;&#x2e;&#99;&#x6f;&#109;&#x2f;&#x40;&#x72;&#x6f;&#104;&#x61;&#x6e;&#x6d;&#105;&#x73;&#116;&#x72;&#x79;&#x32;&#x33;&#49;&#x2f;&#117;&#x6e;&#100;&#x65;&#114;&#115;&#116;&#97;&#110;&#100;&#105;&#x6e;&#103;&#45;&#114;&#x65;&#115;&#110;&#x65;&#116;&#45;&#x61;&#45;&#x64;&#101;&#x65;&#x70;&#x2d;&#x64;&#105;&#118;&#x65;&#45;&#x69;&#x6e;&#x74;&#111;&#45;&#114;&#x65;&#x73;&#x69;&#100;&#x75;&#97;&#x6c;&#45;&#110;&#x65;&#117;&#114;&#97;&#108;&#45;&#x6e;&#101;&#x74;&#119;&#111;&#x72;&#107;&#115;&#x2d;&#x36;&#x64;&#x38;&#99;&#56;&#x63;&#x32;&#50;&#55;&#102;&#100;&#48;</a></p>
<p><a href="https://theaisummer.com/xai/#:~:text=To%20tackle%20the%20aforementioned%20issues%2C,in%20the%20machine%20learning%20community">[16]</a> <a href="https://theaisummer.com/xai/#:~:text=information%20about%20the%20model%E2%80%99s%20decision">[17]</a> <a href="https://theaisummer.com/xai/#:~:text=Deep%20learning%20applications%20have%20drawn,applications%20lack%20explainability%20and%20reliability">[18]</a> Explainable AI (XAI): A survey of recents methods, applications and frameworks | AI Summer</p>
<p><a href="https://theaisummer.com/xai/">https://theaisummer.com/xai/</a></p>
<p><a href="https://medium.com/data-science/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5#:~:text=Learning%20curves%20are%20an%20efficient,may%20fail%20to%20identify%20them">[19]</a> Learning Curve to identify Overfitting and Underfitting in Machine ...</p>
<p><a href="https://medium.com/data-science/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5">https://medium.com/data-science/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5</a></p>
<p><a href="https://medium.com/@aarishalam22/understanding-overfitting-underfitting-and-learning-curves-in-machine-learning-fe19825125c8#:~:text=Understanding%20Overfitting%2C%20Underfitting%2C%20and%20Learning,indicate%20underfitting%2C%20increase%20model">[20]</a> Understanding Overfitting, Underfitting, and Learning Curves in ...</p>
<p><a href="&#x6d;&#97;&#x69;&#108;&#x74;&#x6f;&#58;&#104;&#116;&#116;&#112;&#115;&#x3a;&#x2f;&#47;&#x6d;&#x65;&#100;&#105;&#117;&#109;&#x2e;&#x63;&#x6f;&#x6d;&#47;&#64;&#97;&#x61;&#114;&#x69;&#115;&#x68;&#x61;&#x6c;&#x61;&#x6d;&#x32;&#50;&#x2f;&#117;&#x6e;&#100;&#101;&#x72;&#115;&#x74;&#x61;&#110;&#x64;&#105;&#110;&#103;&#x2d;&#x6f;&#x76;&#101;&#114;&#102;&#x69;&#116;&#116;&#105;&#x6e;&#x67;&#45;&#117;&#x6e;&#x64;&#101;&#114;&#102;&#105;&#116;&#x74;&#105;&#110;&#103;&#x2d;&#97;&#110;&#x64;&#45;&#x6c;&#101;&#97;&#x72;&#110;&#x69;&#x6e;&#103;&#45;&#x63;&#117;&#x72;&#118;&#x65;&#115;&#x2d;&#105;&#x6e;&#x2d;&#x6d;&#97;&#99;&#x68;&#105;&#110;&#101;&#45;&#x6c;&#101;&#x61;&#114;&#x6e;&#x69;&#x6e;&#x67;&#45;&#x66;&#x65;&#x31;&#57;&#56;&#x32;&#53;&#49;&#x32;&#x35;&#x63;&#x38;">&#104;&#116;&#116;&#112;&#115;&#x3a;&#x2f;&#47;&#x6d;&#x65;&#100;&#105;&#117;&#109;&#x2e;&#x63;&#x6f;&#x6d;&#47;&#64;&#97;&#x61;&#114;&#x69;&#115;&#x68;&#x61;&#x6c;&#x61;&#x6d;&#x32;&#50;&#x2f;&#117;&#x6e;&#100;&#101;&#x72;&#115;&#x74;&#x61;&#110;&#x64;&#105;&#110;&#103;&#x2d;&#x6f;&#x76;&#101;&#114;&#102;&#x69;&#116;&#116;&#105;&#x6e;&#x67;&#45;&#117;&#x6e;&#x64;&#101;&#114;&#102;&#105;&#116;&#x74;&#105;&#110;&#103;&#x2d;&#97;&#110;&#x64;&#45;&#x6c;&#101;&#97;&#x72;&#110;&#x69;&#x6e;&#103;&#45;&#x63;&#117;&#x72;&#118;&#x65;&#115;&#x2d;&#105;&#x6e;&#x2d;&#x6d;&#97;&#99;&#x68;&#105;&#110;&#101;&#45;&#x6c;&#101;&#x61;&#114;&#x6e;&#x69;&#x6e;&#x67;&#45;&#x66;&#x65;&#x31;&#57;&#56;&#x32;&#53;&#49;&#x32;&#x35;&#x63;&#x38;</a></p>
<p><a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=For%20an%20overfit%20model%2C%20the,on%20unseen%20data%20is%20deteriorating">[21]</a> <a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=the%20validation%20loss%20stops%20decreasing,on%20unseen%20data%20is%20deteriorating">[22]</a> <a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=A%20significant%20gap%20between%20the,worse%20on%20the%20validation%20set">[23]</a> <a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/#:~:text=,on%20unseen%20data%20as%20well">[24]</a> Learning Curve To Identify Overfit &amp; Underfit - GeeksforGeeks</p>
<p><a href="https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/">https://www.geeksforgeeks.org/machine-learning/learning-curve-to-identify-overfit-underfit/</a></p>
<p><a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=While%20accuracy%20is%20often%20the,For%20example">[25]</a> <a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=In%20the%20world%20of%20machine,learn.%20Let%E2%80%99s%20dive%20in">[26]</a> <a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=,classifying%20important%20emails%20as%20spam">[27]</a> <a href="https://medium.com/@piyushkashyap045/understanding-precision-recall-and-f1-score-metrics-ea219b908093#:~:text=,off">[28]</a> Understanding Precision, Recall, and F1 Score Metrics | by Piyush Kashyap | Medium</p>
<p><a href="&#x6d;&#97;&#x69;&#108;&#116;&#x6f;&#58;&#x68;&#116;&#x74;&#x70;&#115;&#x3a;&#47;&#47;&#x6d;&#101;&#x64;&#x69;&#x75;&#109;&#x2e;&#99;&#x6f;&#109;&#x2f;&#x40;&#x70;&#x69;&#121;&#117;&#x73;&#104;&#107;&#x61;&#x73;&#x68;&#x79;&#97;&#112;&#48;&#x34;&#x35;&#x2f;&#x75;&#110;&#100;&#x65;&#x72;&#x73;&#x74;&#x61;&#110;&#100;&#x69;&#110;&#103;&#x2d;&#112;&#x72;&#101;&#99;&#x69;&#115;&#x69;&#111;&#110;&#x2d;&#114;&#101;&#99;&#x61;&#108;&#x6c;&#x2d;&#x61;&#110;&#x64;&#45;&#x66;&#49;&#x2d;&#x73;&#99;&#111;&#114;&#x65;&#45;&#109;&#x65;&#116;&#x72;&#105;&#99;&#115;&#45;&#x65;&#97;&#x32;&#x31;&#x39;&#x62;&#x39;&#x30;&#56;&#x30;&#57;&#x33;">&#x68;&#116;&#x74;&#x70;&#115;&#x3a;&#47;&#47;&#x6d;&#101;&#x64;&#x69;&#x75;&#109;&#x2e;&#99;&#x6f;&#109;&#x2f;&#x40;&#x70;&#x69;&#121;&#117;&#x73;&#104;&#107;&#x61;&#x73;&#x68;&#x79;&#97;&#112;&#48;&#x34;&#x35;&#x2f;&#x75;&#110;&#100;&#x65;&#x72;&#x73;&#x74;&#x61;&#110;&#100;&#x69;&#110;&#103;&#x2d;&#112;&#x72;&#101;&#99;&#x69;&#115;&#x69;&#111;&#110;&#x2d;&#114;&#101;&#99;&#x61;&#108;&#x6c;&#x2d;&#x61;&#110;&#x64;&#45;&#x66;&#49;&#x2d;&#x73;&#99;&#111;&#114;&#x65;&#45;&#109;&#x65;&#116;&#x72;&#105;&#99;&#115;&#45;&#x65;&#97;&#x32;&#x31;&#x39;&#x62;&#x39;&#x30;&#56;&#x30;&#57;&#x33;</a></p>
<p><a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=The%20two%20most%20common%20approaches,for%20hyperparameter%20tuning%20are">[29]</a> <a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=,This%20is%20computationally%20expensive">[30]</a> <a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=,if%20the%20hyperparameter%20is%20continuous">[31]</a> <a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=To%20this%20end%2C%20Bayesian%20Optimization,powerful%20approach%20for%20tuning%20hyperparameters">[32]</a> <a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=Both%20Grid%20search%20and%20Random,find%20the%20most%20optimal%20one">[33]</a> <a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian#:~:text=The%20efficacy%20of%20Bayesian%20Optimization,evident%20from%20the%20image%20below">[34]</a> Grid Search vs. Random Search vs. Bayesian Optimization</p>
<p><a href="https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian">https://blog.dailydoseofds.com/p/grid-search-vs-random-search-vs-bayesian</a></p>
<p><a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=3">[35]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=,Samples">[36]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=,examples%20to%20balance%20the%20dataset">[37]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=SMOTE%20%28Synthetic%20Minority%20Over,nearest%20neighbors">[38]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Instead%20of%20modifying%20the%20dataset%2C,misclassifications%20of%20the%20minority%20class">[39]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Python%20Example%20%28Scikit">[40]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Python%20Example%3A">[41]</a> <a href="https://medium.com/@adnan.mazraeh1993/advanced-class-imbalance-handling-from-basics-to-super-advanced-65722f59c21b#:~:text=Focal%20Loss%20for%20Handling%20Class,Imbalance">[42]</a> Advanced Class Imbalance Handling: From Basics to Super-Advanced | by Adnan Mazraeh | Medium</p>
<p><a href="&#109;&#x61;&#x69;&#x6c;&#x74;&#111;&#x3a;&#x68;&#x74;&#116;&#112;&#115;&#58;&#47;&#x2f;&#x6d;&#101;&#x64;&#105;&#x75;&#x6d;&#x2e;&#x63;&#111;&#x6d;&#x2f;&#64;&#x61;&#100;&#110;&#97;&#110;&#x2e;&#109;&#97;&#122;&#x72;&#97;&#x65;&#x68;&#49;&#57;&#57;&#x33;&#x2f;&#x61;&#x64;&#x76;&#x61;&#110;&#99;&#101;&#100;&#x2d;&#99;&#x6c;&#97;&#x73;&#115;&#x2d;&#105;&#x6d;&#x62;&#97;&#x6c;&#97;&#x6e;&#99;&#101;&#45;&#x68;&#97;&#110;&#100;&#x6c;&#x69;&#110;&#x67;&#x2d;&#x66;&#114;&#111;&#109;&#45;&#98;&#x61;&#x73;&#x69;&#99;&#x73;&#45;&#x74;&#x6f;&#45;&#x73;&#117;&#x70;&#x65;&#114;&#45;&#97;&#100;&#x76;&#x61;&#x6e;&#x63;&#x65;&#x64;&#x2d;&#x36;&#53;&#x37;&#x32;&#50;&#x66;&#53;&#x39;&#99;&#x32;&#x31;&#98;">&#x68;&#x74;&#116;&#112;&#115;&#58;&#47;&#x2f;&#x6d;&#101;&#x64;&#105;&#x75;&#x6d;&#x2e;&#x63;&#111;&#x6d;&#x2f;&#64;&#x61;&#100;&#110;&#97;&#110;&#x2e;&#109;&#97;&#122;&#x72;&#97;&#x65;&#x68;&#49;&#57;&#57;&#x33;&#x2f;&#x61;&#x64;&#x76;&#x61;&#110;&#99;&#101;&#100;&#x2d;&#99;&#x6c;&#97;&#x73;&#115;&#x2d;&#105;&#x6d;&#x62;&#97;&#x6c;&#97;&#x6e;&#99;&#101;&#45;&#x68;&#97;&#110;&#100;&#x6c;&#x69;&#110;&#x67;&#x2d;&#x66;&#114;&#111;&#109;&#45;&#98;&#x61;&#x73;&#x69;&#99;&#x73;&#45;&#x74;&#x6f;&#45;&#x73;&#117;&#x70;&#x65;&#114;&#45;&#97;&#100;&#x76;&#x61;&#x6e;&#x63;&#x65;&#x64;&#x2d;&#x36;&#53;&#x37;&#x32;&#50;&#x66;&#53;&#x39;&#99;&#x32;&#x31;&#98;</a></p>
<p><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=This%20document%20discusses%20techniques%20for,primarily%20to%20predictive%20AI%20systems">[43]</a> <a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=This%20document%20is%20for%20data,releasing%2C%20deployment%20and%20infrastructure%20management">[44]</a> <a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=culture%20and%20practice%20that%20aims,releasing%2C%20deployment%20and%20infrastructure%20management">[45]</a> <a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=However%2C%20the%20real%20challenge%20isn%27t,Credit%20Card%20of%20Technical%20Debt">[48]</a> <a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#:~:text=Data%20scientists%20can%20implement%20and,Credit%20Card%20of%20Technical%20Debt">[54]</a> MLOps: Continuous delivery and automation pipelines in machine learning  |  Cloud Architecture Center  |  Google Cloud</p>
<p><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning">https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning</a></p>
<p><a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Serving%20architecture">[46]</a> <a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Image%3A%20Online%2Freal">[47]</a> <a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=You%20may%20need%20this%20if,stream%20analytics%20or%20online%20serving">[51]</a> <a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Image%3A%20Message,Source%3A%20author">[52]</a> <a href="https://neptune.ai/blog/mlops-architecture-guide#:~:text=Essentially%2C%20it%20joins%20the%20data,time%20transactions%20%28fraud%20detection%20applications">[53]</a> MLOps Architecture Guide</p>
<p><a href="https://neptune.ai/blog/mlops-architecture-guide">https://neptune.ai/blog/mlops-architecture-guide</a></p>
<p><a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/#:~:text=Concept%20drift%20refers%20to%20that,replaced%20with%20a%20new%20set">[49]</a> <a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/#:~:text=your%20model,significant%20prediction%20drift%20sets%20in">[50]</a> Machine learning model monitoring: Best practices | Datadog</p>
<p><a href="https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/">https://www.datadoghq.com/blog/ml-model-monitoring-in-production-best-practices/</a></p>
<p><a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=Optimization%20techniques%20like%20pruning%2C%20quantization%2C,vital%20for%20improving%20computational%20efficiency">[55]</a> <a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=,performance%20with%20less%20computational%20demand">[56]</a> <a href="https://neptune.ai/blog/deep-learning-model-optimization-methods#:~:text=In%20this%20article%2C%20I%E2%80%99ll%20review,apply%20them%20in%20your%20projects">[57]</a> Deep Learning Model Optimization Methods</p>
<p><a href="https://neptune.ai/blog/deep-learning-model-optimization-methods">https://neptune.ai/blog/deep-learning-model-optimization-methods</a></p>
<p><a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=2022%EB%85%84%207%EC%9B%94%2C%20Open%20AI%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C,%EA%B7%B8%EB%9F%B0%20%EB%8B%A4%EC%9D%8C%20ChatGPT%EA%B0%80%20%EC%99%94%EC%8A%B5%EB%8B%88%EB%8B%A4">[59]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EC%83%9D%EC%84%B1%20AI%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%80%20%EA%B8%B0%EC%A1%B4%20%EB%8D%B0%EC%9D%B4%ED%84%B0,%EC%97%86%EB%8A%94%20%EC%99%84%EC%A0%84%ED%9E%88%20%EC%83%88%EB%A1%9C%EC%9A%B4%20%EC%BD%98%ED%85%90%EC%B8%A0%EB%A5%BC%20%EC%83%9D%EC%84%B1%ED%95%A9%EB%8B%88%EB%8B%A4">[61]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=2022%EB%85%84%207%EC%9B%94%2C%20Open%20AI%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C,%EA%B7%B8%EB%9F%B0%20%EB%8B%A4%EC%9D%8C%20ChatGPT%EA%B0%80%20%EC%99%94%EC%8A%B5%EB%8B%88%EB%8B%A4">[62]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EA%B0%80%EC%9E%A5%20%EC%9E%98%20%EC%95%8C%EB%A0%A4%EC%A7%84%20%EC%83%9D%EC%84%B1%20AI,%EB%B3%80%EC%A2%85%EC%9D%80%20%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%A5%BC%20%EC%83%9D%EC%84%B1%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%82%AC%EC%9A%A9%EB%90%A9%EB%8B%88%EB%8B%A4">[63]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=LLM%EC%9D%80%20%EA%B5%90%EC%9C%A1%20%EA%B0%90%EB%8F%85%EC%9D%B4%20%EA%B1%B0%EC%9D%98%20%EB%98%90%EB%8A%94,%EC%83%9D%EC%84%B1%ED%95%A0%20%EC%88%98%20%EC%9E%88%EB%8A%94%20%ED%95%99%EC%8A%B5%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9E%85%EB%8B%88%EB%8B%A4">[64]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EA%B3%A0%EA%B0%9D%EC%9D%98%20%EC%A7%88%EB%AC%B8%EC%97%90%20%EB%8B%B5%ED%95%98%EA%B1%B0%EB%82%98%20%EB%AC%B8%EC%9E%90%2C%20%EC%86%8C%EB%A6%AC%2C,%ED%8F%AC%ED%95%A8%ED%95%98%EB%8A%94%20%EB%8B%A4%EC%96%91%ED%95%9C%20%EC%96%91%EC%8B%9D%EC%9D%B4%20%EC%A6%9D%EA%B0%80%ED%95%98%EA%B3%A0%20%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4">[65]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,Federated%20learning">[68]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=%EC%97%B0%ED%95%A9%20%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9D%BC%EB%8A%94%20%EC%9D%B8%EA%B3%B5%20%EC%A7%80%EB%8A%A5%EC%9D%98%20%EC%83%88%EB%A1%9C%EC%9A%B4,%EC%84%B1%EB%8A%A5%E2%80%9D%EC%9D%84%20%EB%AA%A8%EB%91%90%20%EC%82%AC%EC%9A%A9%ED%95%A0%20%EC%88%98%20%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4">[69]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,AIoT">[70]</a> <a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/#:~:text=,MLOps">[72]</a> 2023년 기대되는 AI 기술 트렌드 10가지 - 디지털 인사인트 매거진</p>
<p><a href="https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/">https://digit2sight.com/2023%eb%85%84-%ea%b8%b0%eb%8c%80%eb%90%98%eb%8a%94-ai-%ea%b8%b0%ec%88%a0-%ed%8a%b8%eb%a0%8c%eb%93%9c-10%ea%b0%80%ec%a7%80/</a></p>
<p><a href="https://viso.ai/deep-learning/efficientnet/#:~:text=EfficientNet%20is%20a%20Convolutional%20Neural,high%20accuracy%20with%20computational%20efficiency">[66]</a> <a href="https://viso.ai/deep-learning/efficientnet/#:~:text=Increasing%20the%20complexity%20of%20CNNs,which%20demands%20more%20computational%20resources">[67]</a> EfficientNet: Optimizing Deep Learning Efficiency</p>
<p><a href="https://viso.ai/deep-learning/efficientnet/">https://viso.ai/deep-learning/efficientnet/</a></p>
<p><a href="https://careerly.co.kr/comments/75278#:~:text=MLOps%202023%EB%85%84%EC%9D%98%20%EB%AA%87%20%EA%B0%80%EC%A7%80%20%EC%A3%BC%EC%9A%94,%EB%A7%8E%EC%9D%80%20%EB%8F%84%EC%9B%80%EC%9D%B4%20%EB%90%A0%20%EA%B1%B0%EB%9D%BC%20%EB%AF%BF%EC%8A%B5%EB%8B%88%EB%8B%A4">[71]</a> 2023년 기대되는 AI 기술 트렌드 10가지 | 커리어리</p>
<p><a href="https://careerly.co.kr/comments/75278">https://careerly.co.kr/comments/75278</a></p>
