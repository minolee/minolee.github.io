<h1 id="ai-">AI 직무 평가 대비 강의 자료 (기술 블로그 스타일)</h1>
<h2 id="1-">1. 데이터 전처리</h2>
<h3 id="-bias-">데이터 수집과 편향 (Bias)</h3>
<ul>
<li><strong>시험 포인트:</strong> 데이터 수집 시 편향 최소화가 중요합니다. 한 명의 전문가만 레이블링하면 일관성은 생기지만 개인적 편향이 전체 데이터셋에 반영됩니다.  </li>
<li><strong>실무 사례:</strong> ImageNet도 초기에는 서구권 데이터 위주라서 인종·문화적 편향 문제가 논의되었습니다. Google의 “Inclusive Images Challenge(2018)”는 다양한 지역 데이터를 추가해 이를 완화하고자 했습니다.  </li>
<li><strong>연구 참고:</strong>  </li>
<li>Torralba &amp; Efros, <em>Unbiased Look at Dataset Bias</em> (CVPR 2011).  </li>
<li>Mitchell et al., <em>Model Cards for Model Reporting</em> (FAT* 2019).  <h3 id="-normalization-vs-standardization-">데이터 정제 (Normalization vs. Standardization)</h3>
</li>
<li><strong>시험 포인트:</strong>  </li>
<li>Min-Max Normalization: [0,1] 구간으로 스케일링 → 이상치(outlier)에 민감.  </li>
<li>Standardization: 평균 0, 표준편차 1로 변환 → 회귀, PCA에 적합.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>LeCun et al. (1998) MNIST → 입력 데이터 정규화를 통해 빠른 학습 달성.  </li>
<li>Ioffe &amp; Szegedy, <em>Batch Normalization</em> (ICML 2015).  <h3 id="-data-augmentation-">데이터 증강 (Data Augmentation)</h3>
</li>
<li><strong>시험 포인트:</strong> 자율주행 Semantic Segmentation에는 Random Erasing이 적합. 이는 가려짐 상황을 학습시켜 모델을 더 강인하게 만듭니다.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Zhong et al., <em>Random Erasing Data Augmentation</em> (AAAI 2020).  </li>
<li>CutMix, Mixup, AugMix 등은 분류 과제에 강점.  </li>
</ul>
<hr>
<h2 id="2-ai-">2. AI 모델 개발</h2>
<h3 id="-self-supervised-learning">아키텍처 설계 &amp; Self-Supervised Learning</h3>
<ul>
<li><strong>시험 포인트:</strong> SimCLR, BYOL, MAE, RotNet 등 self-supervised 기법의 핵심 이해.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Chen et al., <em>SimCLR</em> (ICML 2020).  </li>
<li>Grill et al., <em>BYOL</em> (NeurIPS 2020).  </li>
<li>He et al., <em>MAE</em> (CVPR 2022).  <h3 id="explainable-ai-xai-">Explainable AI (XAI)</h3>
</li>
<li><strong>시험 포인트:</strong> CAM vs. Grad-CAM 구분. CAM은 FC layer 가중치 기반, Grad-CAM은 손실 기울기 기반.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Zhou et al., <em>CAM</em> (CVPR 2016).  </li>
<li>Selvaraju et al., <em>Grad-CAM</em> (ICCV 2017).  <h3 id="-learning-curve-">모델 학습 &amp; 평가 (Learning Curve, 지표)</h3>
</li>
<li><strong>시험 포인트:</strong>  </li>
<li>언더피팅: 모델 복잡도 ↑, 특징 ↑ 필요.  </li>
<li>과적합: Dropout, L2 정규화, BatchNorm 등 활용.  </li>
<li>지표: Recall = 안전-critical 환경에서 중요.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Srivastava et al., <em>Dropout</em> (JMLR 2014).  </li>
<li>Powers, <em>Evaluation: Precision, Recall, F-measure</em> (2011).  <h3 id="-hpo-class-imbalance-">모델 튜닝 (HPO &amp; Class Imbalance)</h3>
</li>
<li><strong>시험 포인트:</strong>  </li>
<li>Bayesian Optimization: 효율적 HPO.  </li>
<li>클래스 불균형 → SMOTE, 언더샘플링, Focal Loss 등.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Bergstra &amp; Bengio, <em>Random Search for Hyper-Parameter Optimization</em> (JMLR 2012).  </li>
<li>Lin et al., <em>Focal Loss</em> (ICCV 2017).  </li>
</ul>
<hr>
<h2 id="3-ai-">3. AI 시스템 구축</h2>
<h3 id="ml-pipeline-">ML Pipeline &amp; 배포 전략</h3>
<ul>
<li><strong>시험 포인트:</strong> Model-in-service vs. Model-as-service 비교.  </li>
<li>In-service: 기존 인프라 재활용, 서버 리소스 점유↑.  </li>
<li>As-service: 확장성↑, 독립적 관리 용이.  </li>
<li><strong>사례:</strong> Google TFX, Kubeflow / Docker-K8s 기반 CI/CD.  <h3 id="mlops-">MLOps &amp; 자동화</h3>
</li>
<li><strong>시험 포인트:</strong> MLOps maturity level: 수동(Level 0) ↔ 자동화(Level 1+).  </li>
<li><strong>사례/백서:</strong>  </li>
<li>Google Cloud, <em>Continuous Training for ML</em> (2020).  </li>
<li>AWS Sagemaker, Azure ML docs.  <h3 id="-">모델 최적화</h3>
</li>
<li><strong>시험 포인트:</strong> 모델 경량화 기법 → Pruning, Quantization, EfficientNet의 Compound Scaling.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Han et al., <em>Deep Compression</em> (ICLR 2016).  </li>
<li>Tan &amp; Le, <em>EfficientNet</em> (ICML 2019).  </li>
</ul>
<hr>
<h2 id="4-ai-">4. 주요 AI 트렌드</h2>
<h3 id="zero-shot-generalized-zero-shot-learning">Zero-shot &amp; Generalized Zero-shot Learning</h3>
<ul>
<li><strong>시험 포인트:</strong> 새로운 클래스 인식 능력.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Xian et al., <em>Zero-shot Learning – A Comprehensive Evaluation</em> (TPAMI 2018).  </li>
<li>Radford et al., <em>CLIP</em> (ICML 2021).  <h3 id="chain-of-thought-prompting">Chain-of-Thought Prompting</h3>
</li>
<li><strong>시험 포인트:</strong> 단계적 추론 유도.  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Wei et al., <em>Chain-of-Thought Prompting</em> (NeurIPS 2022).  <h3 id="nas-darts">NAS &amp; DARTS</h3>
</li>
<li><strong>시험 포인트:</strong> Neural Architecture Search, 미분 가능 탐색(DARTS).  </li>
<li><strong>연구/사례:</strong>  </li>
<li>Zoph &amp; Le, <em>Neural Architecture Search</em> (ICLR 2017).  </li>
<li>Liu et al., <em>DARTS</em> (ICLR 2019).  </li>
</ul>
<hr>
<p>🔹 Level 0: 수동 운영 (Manual)</p>
<p>모델 개발, 배포, 재학습을 사람이 직접 처리.</p>
<p>데이터 준비 → 학습 → 평가 → 배포가 모두 단발성 프로젝트 성격.</p>
<p>재현성 부족, 자동화 없음.</p>
<p>스타트업·연구 프로젝트 초기 단계에서 흔히 나타남.</p>
<p>🔹 Level 1: 자동화된 파이프라인 (ML Pipeline Automation)</p>
<p>데이터 전처리, 학습, 평가, 배포 단계를 CI/CD 파이프라인처럼 연결.</p>
<p>코드 변경 → 자동 재학습 및 배포 가능.</p>
<p>Kubeflow, TFX, MLflow 같은 도구 활용.</p>
<p>핵심: 모델 개발부터 배포까지의 반복을 자동화.</p>
<p>🔹 Level 2: 자동 모니터링 및 재학습 (Continuous Training / MLOps)</p>
<p>운영 중 모델을 실시간 모니터링.</p>
<p>성능 지표, 데이터 분포, drift 탐지.</p>
<p>이상 발생 시 자동으로 재학습 파이프라인 실행.</p>
<p>데이터 드리프트·개념 드리프트 대응 가능.</p>
<p>모델 레지스트리와 버전 관리 체계 포함.</p>
<p>🔹 Level 3: 완전 자동화된 ML 시스템 (Full MLOps / AutoMLOps)</p>
<p>데이터 수집 → 학습 → 배포 → 모니터링 → 재학습까지 엔드-투-엔드 자동화.</p>
<p>인적 개입 최소화, 지속적인 모델 개선.</p>
<p>AutoML 기법과 결합되어, 새로운 태스크에 자동으로 적응 가능.</p>
<p>대규모 기업 환경에서 목표로 삼는 최종 단계.</p>
<p>📌 정리:</p>
<p>Level 0 = 수동, ad-hoc</p>
<p>Level 1 = 학습/배포 자동화 (파이프라인화)</p>
<p>Level 2 = 모니터링·재학습 자동화 (지속적 운영)</p>
<p>Level 3 = 완전 자동화, AutoML과 결합</p>
<p><a href="https://velog.io/@leesjpr/MLOps-%EC%88%98%EC%A4%80">참고</a></p>
