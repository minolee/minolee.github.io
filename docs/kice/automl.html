<h1 id="automl-">AutoML의 부상: 배경, 핵심 연구 분야 및 최신 동향</h1>
<h2 id="-automl-">등장 배경: AutoML의 필요성과 등장 계기</h2>
<p>머신러닝 모델 개발은 데이터 전처리, 특징 공학, 알고리즘 선택, 하이퍼파라미터 튜닝 등 여러 복잡한 단계를 거칩니다<a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=data%20points%20to%20be%20used,by%20the%20machine%20learning%20expert">[1]</a>. 이러한 과정은 전문 지식과 많은 시간·자원이 요구되어, <strong>비전문가가 접근하기 어려운 장벽</strong>으로 작용해왔습니다. 특히 딥러닝 모델의 경우 신경망 아키텍처 설계까지 필요하므로 난이도가 더욱 높습니다<a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=After%20these%20steps%2C%20practitioners%20must,by%20the%20machine%20learning%20expert">[2]</a>. AutoML(Automated Machine Learning)은 이와 같은 <strong>모델 개발 전 과정을 자동화</strong>하여 문제를 해결하고자 등장했습니다<a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=an%20artificial%20intelligence,designed%20models.%5B%204">[3]</a>. AutoML의 목표는 <strong>머신러닝 비전문가도 손쉽게 ML 기법을 활용</strong>할 수 있도록 하는 것이며, 자동화를 통해 개발 시간을 단축하고 경우에 따라 인간 전문가가 수작업으로 설계한 모델보다 높은 성능의 모델을 얻는 것까지 가능하게 합니다<a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=an%20artificial%20intelligence,designed%20models.%5B%204">[3]</a>. 실제로 AutoML은 복잡한 ML 파이프라인을 자동화함으로써 <strong>간소한 솔루션을 더 빠르게 구축</strong>하고, 숙련된 연구자들조차도 놓칠 수 있는 최적 모델을 발견해내는 사례를 보여주고 있습니다<a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=an%20artificial%20intelligence,designed%20models.%5B%204">[3]</a>.</p>
<p>요컨대, <strong>모델 개발의 복잡성 증가와 전문인력 부족</strong>이라는 배경 속에서 AutoML이 부상하게 되었습니다. AutoML은 데이터 준비에서부터 모델 선정·튜닝, 그리고 배포에 이르는 과정을 알고리즘적으로 수행하여 <strong>ML의 민주화(democratization)</strong>를 이끌고 있습니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=accessibility%20challenge%20by%20attempting%20to,2021%29%2C%20and%20platforms%20like">[4]</a>. 이는 기업이나 조직이 머신러닝의 이점을 누리면서도 전문 인력 의존도를 낮추고, ML 솔루션 구현에 소요되는 시간과 비용을 크게 절감할 수 있게 합니다. 이러한 배경에서 AutoML 연구가 활발히 전개되어 왔으며, 아래에서는 그 주요 흐름을 살펴보겠습니다.</p>
<h2 id="-">주요 연구 흐름 및 대표 기법</h2>
<p>AutoML 분야는 다양한 방향으로 연구되어 왔으며, 그 중에서도 <strong>신경망 구조 검색(NAS)</strong>, <strong>하이퍼파라미터 최적화(HPO)</strong>, <strong>특징(feature) 공학 자동화</strong>, <strong>ML 파이프라인 최적화 및 메타러닝</strong> 등이 핵심 흐름으로 자리잡았습니다. 각 분야별로 대표적인 연구와 기법을 살펴보겠습니다.</p>
<h3 id="neural-architecture-search-nas-">Neural Architecture Search (NAS; 신경망 아키텍처 검색)</h3>
<p>NAS는 <strong>신경망 구조 자체를 자동으로 설계</strong>하는 분야로, 딥러닝 모델의 성능을 좌우하는 네트워크 구조를 인간 대신 탐색합니다. 2017년 구글 브레인의 Zoph &amp; Le 연구는 NAS의 시초격으로, <strong>강화학습</strong>을 이용한 신경망 아키텍처 검색을 제안했습니다. 이 방법에서는 RNN 기반의 컨트롤러(Controller)가 신경망 구조를 표현하는 문자열(모델 설명)을 생성하고, 해당 구조를 자식 네트워크로 학습시킨 후 성능을 <strong>보상(reward)</strong>으로 받아 다시 컨트롤러를 학습시키는 방식을 취했습니다<a href="https://arxiv.org/abs/1611.01578#:~:text=understanding,the%20Penn%20Treebank%20dataset%2C%20our">[5]</a>. 이렇게 훈련된 NAS 컨트롤러는 CIFAR-10 등의 데이터셋에서 인간 전문가가 고안한 최고 성능 모델과 맞먹는 신경망 구조를 <strong>자동으로 발견</strong>해냈고, 일부 경우 인간 모델보다 더 낮은 오류율을 달성하기도 했습니다<a href="https://arxiv.org/abs/1611.01578#:~:text=understanding,the%20Penn%20Treebank%20dataset%2C%20our">[5]</a>. 이는 NAS가 충분한 자원만 있다면 전문가 수준의 네트워크 설계를 자동화할 수 있음을 보여준 획기적인 결과였습니다.</p>
<p>그러나 초기 NAS 기법은 수만 개의 후보 구조를 일일이 학습하여 평가해야 하므로 <strong>막대한 계산 비용</strong>이 드는 문제가 있었습니다. 이를 개선하기 위한 연구로 2018년 제안된 <strong>ENAS(Efficient NAS)</strong> 기법이 있습니다. ENAS는 <strong>파라미터 공유</strong>(weight sharing) 아이디어를 도입하여, 컨트롤러가 생성한 자식 네트워크들이 <strong>공통으로 가중치 일부를 공유</strong>하도록 함으로써 일일이 처음부터 다시 학습하지 않아도 되게 만들었습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5%20%EA%B8%B0%EB%B0%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98,%EC%9E%AC%ED%99%9C%EC%9A%A9%EC%9D%B4%20%EC%97%86%EC%96%B4%20%EA%B3%84%EC%82%B0%20%EB%B3%B5%EC%9E%A1%EB%8F%84%20%EB%AC%B8%EC%A0%9C%EC%97%90">[6]</a>. 이 방법을 통해 기존 NAS 대비 <strong>검색 비용을 대폭 절감</strong>하면서도 성능에 큰 손실 없이 효율적으로 우수한 구조를 찾을 수 있음을 보였습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5%20%EA%B8%B0%EB%B0%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98,%EC%9E%AC%ED%99%9C%EC%9A%A9%EC%9D%B4%20%EC%97%86%EC%96%B4%20%EA%B3%84%EC%82%B0%20%EB%B3%B5%EC%9E%A1%EB%8F%84%20%EB%AC%B8%EC%A0%9C%EC%97%90">[6]</a>.</p>
<p>또 다른 방향으로, <strong>미분 가능 NAS</strong> 연구도 주요한 흐름입니다. 2018년 제안된 <strong>DARTS(Differentiable Architecture Search)</strong>는 NAS 문제를 연속적 공간으로 <strong>완화(relaxation)</strong>하여 <strong>경사하강법</strong>으로 최적화하는 획기적인 접근을 선보였습니다<a href="https://arxiv.org/abs/1806.09055#:~:text=,differentiable%20techniques">[7]</a>. 기존에는 신경망 구조 선택이 이산적인 문제라서 진화나 강화학습처럼 비미분 최적화에 의존했지만, DARTS는 아키텍처 선택 변수를 연속 매개변수로 두어 신경망 구조를 <strong>실시간으로 학습</strong>할 수 있게 했습니다<a href="https://arxiv.org/abs/1806.09055#:~:text=,for%20language%20modeling%2C%20while%20being">[8]</a>. 그 결과, CIFAR-10 등에서 높은 성능의 CNN 구조를 찾는 데 소요되는 시간이 기존 방법들보다 <strong>수십~수백 배 이상 단축</strong>되었고, 최종 성능도 최첨단 기법에 견주는 수준을 보였습니다<a href="https://arxiv.org/abs/1806.09055#:~:text=non,differentiable%20techniques">[9]</a>. 이처럼 <strong>강화학습</strong>, <strong>진화적 알고리즘</strong>, <strong>미분가능 최적화</strong> 등을 활용한 다양한 NAS 방법들이 등장하면서, 신경망 설계의 자동화가 현실화되고 있습니다. 현재 NAS 연구는 <strong>셀 기반 구조 검색</strong>(예: NASNet의 셀 구조 활용)으로 검색 공간을 정의하고, <strong>검증 데이터셋</strong>을 이용해 후보 구조의 성능을 빠르게 <strong>추정하는 전략</strong>을 공통적으로 채택하는 추세입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%98%90%ED%95%9C%2C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,30%5D%20%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C%20%EC%A0%95%ED%99%95%EB%8F%84%20%EB%8C%80%EB%B9%84">[10]</a>.</p>
<p>대표 논문으로는 NAS 분야를 개척한 Zoph &amp; Le의 논문(ICLR 2017)<a href="https://arxiv.org/abs/1611.01578#:~:text=understanding,the%20Penn%20Treebank%20dataset%2C%20our">[5]</a>, 효율성을 높인 ENAS(Pham 등, 2018)<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5%20%EA%B8%B0%EB%B0%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98,%EC%9E%AC%ED%99%9C%EC%9A%A9%EC%9D%B4%20%EC%97%86%EC%96%B4%20%EA%B3%84%EC%82%B0%20%EB%B3%B5%EC%9E%A1%EB%8F%84%20%EB%AC%B8%EC%A0%9C%EC%97%90">[6]</a>, 그리고 미분가능 NAS를 제시한 DARTS(ICLR 2019)<a href="https://arxiv.org/abs/1806.09055#:~:text=,differentiable%20techniques">[7]</a> 등을 꼽을 수 있습니다. 이들 연구는 각각 NAS의 <strong>효과성</strong>, <strong>효율성</strong>, <strong>확장성</strong>을 크게 진전시켰습니다.</p>
<h3 id="-hyperparameter-optimization-hpo-">하이퍼파라미터 최적화 (Hyperparameter Optimization, HPO)</h3>
<p>하이퍼파라미터 최적화는 <strong>모델의 최적 하이퍼파라미터 설정을 자동으로 탐색</strong>하는 분야입니다. 전통적으로 하이퍼파라미터 튜닝은 <strong>그리드 탐색</strong>(격자 형태로 조합을 체계적으로 시도)이나 <strong>랜덤 탐색</strong>에 의존해왔습니다. 하지만 그리드 탐색은 조합 수가 조금만 늘어도 연산량이 기하급수적으로 증가하고, 랜덤 탐색은 효율은 높지만 <strong>체계적 가이드가 부족</strong>한 한계가 있습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=1">[11]</a><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%98%88%EC%B2%98%EB%9F%BC%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%EA%B5%AC%EA%B0%84%20%EB%82%B4%EC%97%90%EC%84%9C,%EB%B0%9C%EA%B2%AC%ED%95%A0%20%EC%88%98%20%EC%9E%88%EB%8A%94%20%EA%B0%80%EB%8A%A5%EC%84%B1%EC%9D%84%20%EB%86%92%EC%98%80%EB%8B%A4">[12]</a>.</p>
<p>이를 보완하기 위해 <strong>베이지안 최적화</strong>가 HPO에 널리 도입되었습니다. 베이지안 최적화는 현재까지의 탐색 결과를 <strong>서로게이트 모델</strong>(대체 모델)로 학습하여, 다음 탐색할 후보를 제안하는 <strong>획득 함수</strong>(acquisition function)를 통해 <strong>효율적으로 최적해를 수렴</strong>하는 방법입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=2">[13]</a><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%9C%84%EC%99%80%20%EA%B0%99%EC%9D%80%20%EB%B0%A9%EC%8B%9D%EC%9C%BC%EB%A1%9C%20%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94%20%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88,%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%EC%B5%9C%EC%A0%81%ED%99%94%20%EA%B8%B0%EC%88%A0%EC%9D%B4%20%EB%93%B1%EC%9E%A5%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[14]</a>. 2012년 Snoek 등 연구<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%9C%84%EC%99%80%20%EA%B0%99%EC%9D%80%20%EB%B0%A9%EC%8B%9D%EC%9C%BC%EB%A1%9C%20%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94%20%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88,%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%EC%B5%9C%EC%A0%81%ED%99%94%20%EA%B8%B0%EC%88%A0%EC%9D%B4%20%EB%93%B1%EC%9E%A5%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[14]</a> 이후로 베이지안 최적화는 하이퍼파라미터 튜닝의 주류 기법이 되었는데, 복잡한 모델일수록 1회 평가 비용이 크기 때문에 순수 베이지안 최적화만으로는 시간이 많이 걸리는 경우가 많았습니다<a href="https://arxiv.org/abs/1807.01774#:~:text=,consistently%20outperforms%20both%20Bayesian%20optimization">[15]</a>. 특히 최신 딥러닝에 적용할 때 <strong>수십 수백 번의 학습</strong>을 해야 하는 베이지안 접근은 현실적으로 어려움이 있었고, 이를 개선하기 위한 다양한 연구가 등장했습니다.</p>
<p>그 중 최근 주목받은 기법이 <strong>멀티-피델리티(multifidelity) 기반 최적화</strong>입니다. 이는 <strong>적은 리소스로 대략적인 성능을 평가</strong>하여 나쁜 설정을 조기에 제거하고, 유망한 설정에만 추가 자원을 할당하는 방식입니다. 대표적으로 Li 등(2018)이 제안한 <strong>Hyperband</strong> 알고리즘이 있습니다. Hyperband는 일정 예산 내에서 <strong>무작위로 여러 설정을 부분 학습</strong>시킨 뒤, <strong>성능이 낮은 절반을 과감히 잘라내고</strong> 남은 절반을 더 긴 학습으로 이어가는 <strong>서세(iterative) 방식을 반복</strong>합니다<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=match%20at%20L2112%20A%20popular,performing%20ones%20early">[16]</a>. 이렇게 하면 한정된 예산으로도 많은 후보를 시험해볼 수 있고, <strong>낮은 성능의 후보를 초기에 제거</strong>하여 리소스를 절약할 수 있습니다<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=match%20at%20L2112%20A%20popular,performing%20ones%20early">[16]</a>. Hyperband는 기존 <strong>Successive Halving</strong> 기법을 확장한 것으로, 탐색 시작 시점의 후보 수와 단계별 자원 증분을 달리하는 <strong>여러 bracket을 병렬로 수행</strong>하여 탐색 효율을 극대화합니다<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=Hyperband%20solves%20this%20problem%20by,where">[17]</a><a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=An%20example%20Hyperband%20schedule%20is,hyperparameter%20configurations%3B%20note%20that%20each">[18]</a>. 이 방법은 랜덤 탐색의 <strong>폭넓은 탐색</strong>과 조기중단 전략의 <strong>자원 절약</strong>을 결합해 <strong>빠른 임의 성능 향상</strong>을 이루었습니다.</p>
<p>또 하나의 중요한 발전은 <strong>BOHB</strong>입니다. BOHB(Falkner 등, 2018)는 <strong>Bayesian Optimization과 Hyperband의 장점을 결합</strong>한 기법으로, <strong>베이지안 최적화의 지능적 탐색</strong>에 <strong>Hyperband의 속도</strong>를 접목했습니다<a href="https://arxiv.org/abs/1807.01774#:~:text=infeasible,forward%20neural%20networks%2C%20Bayesian">[19]</a>. 구체적으로, Hyperband가 무작위로 후보를 선택하던 단계를 베이지안 최적화로 대체하여 <strong>성능 향상 가능성이 높은 후보에 우선순위</strong>를 두고 평가합니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=match%20at%20L188%20Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[20]</a><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4%20%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[21]</a>. BOHB는 Tree Parzen Estimator(TPE) 기반의 서러게이트 모델을 사용하여 구현의 단순성과 효율성을 높였으며, 다중 작업 병렬화까지 지원하여 32개의 워커를 사용하면 <strong>약 15배까지 탐색 속도를 향상</strong>시킬 수 있음을 보였습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=BOHB,8%5D%EA%B0%80">[22]</a><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4%20%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[21]</a>. 결과적으로 BOHB는 베이지안 최적화 단독이나 Hyperband 단독보다도 <strong>일관되게 우수한 성능</strong>을 다양한 문제(고차원 함수, SVM, 신경망, 강화학습 등)에서 달성했습니다<a href="https://arxiv.org/abs/1807.01774#:~:text=configurations%20as%20quickly,the%20same%20time%20being%20conceptually">[23]</a>.</p>
<p>요약하면, HPO 분야에서는 <strong>베이지안 최적화</strong>를 기반으로 한 기법들이 주류를 이루면서도 <strong>멀티-피델리티 전략(Hyperband 등)</strong>과 <strong>결합 기법(BOHB 등)</strong>을 통해 <strong>탐색 속도와 확실성</strong>을 모두 잡는 방향으로 발전해 왔습니다. 이 외에도 진화 알고리즘, <strong>Population Based Training(PBT)</strong>, <strong>PSO(입자군집화)</strong>, 서러게이트 모델 등 다양한 접근들이 시도되었지만, 현재는 Hyperband 계열과 BOHB 계열이 실용적인 표준으로 자리잡았습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=match%20at%20L364%20%EC%97%B0%EA%B5%AC%EB%93%A4%EC%9D%B4%20%EC%A0%9C%EC%95%88%EB%90%98%EA%B3%A0,%ED%92%80%EA%B3%A0%EC%9E%90%20%ED%95%98%EB%8A%94%20%EC%97%B0%EA%B5%AC%EB%93%A4%EB%8F%84%20%EC%B6%9C%ED%98%84%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[24]</a>. 더 나아가 최근에는 <strong>신경망 구조 탐색(NAS)과 하이퍼파라미터 탐색을 통합적으로 풀려는 연구</strong><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%97%B0%EA%B5%AC%EB%93%A4%EC%9D%B4%20%EC%A0%9C%EC%95%88%EB%90%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4,%ED%92%80%EA%B3%A0%EC%9E%90%20%ED%95%98%EB%8A%94%20%EC%97%B0%EA%B5%AC%EB%93%A4%EB%8F%84%20%EC%B6%9C%ED%98%84%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[25]</a>도 나오고 있는데, 이는 뒤에서 다시 언급하겠습니다.</p>
<h3 id="feature-engineering-">Feature Engineering 자동화 (자동 특징 공학)</h3>
<p><strong>특징 공학(feature engineering)</strong>은 모델의 성능을 좌우하는 중요한 단계이지만, 도메인 지식과 많은 수작업을 필요로 합니다. AutoML의 한 흐름은 이 <strong>특징 생성과 선택 과정을 자동화</strong>하여 데이터 사이언티스트의 부담을 줄이는 것입니다. 예를 들어 <strong>AutoFeat</strong>(Franziska Horn 등, 2019)이라는 오픈소스 라이브러리는 <strong>비선형 조합 특징을 자동 생성</strong>한 뒤, 그 중 <strong>유의미한 소수의 특징을 선택</strong>하여 원래의 선형 모델 성능을 크게 향상시키면서도 모델의 해석 가능성은 유지할 수 있음을 보였습니다<a href="https://arxiv.org/abs/1901.07329#:~:text=feature%20engineering%20and%20selection%20capabilities,meaningful%20features%20is%20selected%2C%20which">[26]</a>. AutoFeat는 다단계 과정으로 동작하는데, 우선 주어진 입력 피처들로부터 다항식 변환, 곱셈, 로그 등 <strong>다양한 수학적 변환을 조합</strong>하여 방대한 후보 특징들을 만들어내고, 이어서 그중 가장 효과적인 특징들을 탐색해 최종 모델에 포함시킵니다<a href="https://arxiv.org/abs/1901.07329#:~:text=feature%20engineering%20and%20selection%20capabilities,meaningful%20features%20is%20selected%2C%20which">[26]</a>. 이를 통해 <strong>복잡한 비선형 모델의 성능을 선형 모델로도 달성</strong>할 수 있도록 하여, 모델을 보다 <strong>투명하고 설명 가능</strong>하게 만들면서도 예측 정확도를 높이는 성과를 얻었습니다<a href="https://arxiv.org/abs/1901.07329#:~:text=feature%20engineering%20and%20selection%20capabilities,meaningful%20features%20is%20selected%2C%20which">[26]</a>.</p>
<p>또 다른 대표적인 기법은 <strong>딥(feature) Feature Synthesis (DFS)</strong>입니다. DFS는 MIT에서 제안한 알고리즘으로, <strong>관계형 데이터베이스</strong> 내 여러 테이블에 걸쳐 <strong>자동으로 새로운 특징을 생성</strong>합니다<a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf#:~:text=II,explain%20the%20motivation%20for%20Deep">[27]</a>. 방법은 간단히 말해, <strong>엔티티 간의 관계를 따라가면서</strong> 수치 필드들에 대한 합계, 평균, 최대값 등의 <strong>집계 연산</strong>을 단계적으로 적용해 나가는 것입니다<a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf#:~:text=II,explain%20the%20motivation%20for%20Deep">[27]</a>. 이를 통해 &quot;사용자가 최근 구매한 제품의 평균 가격&quot;, &quot;해당 고객의 주문 횟수&quot; 등과 같은 <strong>유용한 파생 특징들</strong>을 자동으로 만들어냅니다. DFS는 특징을 만들 때 연산을 누적적(stacking)으로 적용할 수 있어서, 한 번의 연산으로 나온 특징을 다시 다른 연산의 입력으로 사용함으로써 <strong>특징 생성의 깊이(depth)</strong>를 늘려갑니다<a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf#:~:text=generates%20features%20for%20relational%20datasets,abstractions%2C%20and%20present%20the%20algorithm">[28]</a>. 예컨대 &quot;고객별 총 주문금액의 표준편차&quot;와 같이 <strong>2단계 이상의 조합 특징</strong>도 생성해낼 수 있으며, 이러한 깊은 특징일수록 잠재적으로 더 복잡한 관계를 포착합니다. DFS는 FeatureTools 등의 오토ML 도구에 구현되어 <strong>사람이 일일이 SQL 쿼리를 작성하지 않아도</strong> 수백 개의 새로운 피처를 자동 생성해주는 것으로 널리 활용되고 있습니다.</p>
<p><strong>구글의 AutoML Tables</strong>와 같은 상용 AutoML 플랫폼 또한 <strong>특징 공학을 자동화</strong>하는 실용 사례입니다. AutoML Tables는 구조화된 표 데이터에 대해 <strong>자동으로 데이터 전처리와 특징 변환, 알고리즘 선택</strong>까지 수행하여 최적 모델을 찾아주는 서비스입니다<a href="https://cloud.google.com/blog/products/ai-machine-learning/new-automl-features-and-end-to-end-workflows-on-ai-platform-pipelines#:~:text=AutoML%20Tables%20%20lets%20you,46%2C%20and%20more">[29]</a>. 사용자는 별다른 코딩 없이 데이터만 업로드하고 몇 번의 클릭으로 <strong>학습을 시작</strong>할 수 있으며, AutoML이 알아서 범주형 변수 인코딩, 누락값 처리, 교차 특성 생성 등을 내부적으로 수행합니다<a href="https://medium.com/googledeveloperseurope/make-your-life-easier-with-automl-tables-on-google-cloud-8a745c4e7f67#:~:text=So%2C%20I%20suggested%20him%20to,results%20ready%20the%20next%20morning">[30]</a>. 한 사례로, NASA Space Apps 해커톤에서 한 참가자가 AutoML Tables를 사용해 <strong>코딩 없이 하룻밤만에 모델을 완성</strong>한 일이 소개되었는데, 데이터 로드부터 학습, 평가, 그리고 배포까지 <strong>모두 GUI와 자동화로 처리</strong>되어 다음 날 바로 예측 결과를 얻을 수 있었다고 합니다<a href="https://medium.com/googledeveloperseurope/make-your-life-easier-with-automl-tables-on-google-cloud-8a745c4e7f67#:~:text=So%2C%20I%20suggested%20him%20to,results%20ready%20the%20next%20morning">[30]</a>. 이처럼 AutoML Tables 등의 플랫폼은 <strong>사전 데이터 처리와 특징 엔지니어링을 내장</strong>하고 있어, 전문지식 없이도 비교적 양질의 특징셋(feature set)을 확보할 수 있도록 도와줍니다.</p>
<h3 id="-">파이프라인 최적화 및 메타러닝</h3>
<p>AutoML의 완성형 목표는 <strong>전체 머신러닝 파이프라인을 자동 구성</strong>하는 것입니다. 여기에는 데이터 전처리, 특징 선택, 알고리즘(모델) 선택, 하이퍼파라미터 튜닝, 앙상블 등에 이르는 <strong>종합적인 워크플로우의 최적화</strong>가 포함됩니다. 이를 위해 <strong>메타러닝(meta-learning)</strong> 개념이 많이 활용됩니다. 메타러닝이란 <strong>과거의 학습 경험으로부터 새로운 학습을 가속</strong>하거나 개선하는 방법으로, AutoML에서는 <strong>이전 데이터셋들에서 어떤 모델과 설정이 잘 작동했는지를 학습</strong>해 새로운 데이터셋에 빠르게 적용하는 데 쓰입니다<a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Meta,the%20need%20for%20manual%20intervention">[31][32]</a>.</p>
<p>대표적인 AutoML 프레임워크로 <strong>Auto-sklearn</strong>이 있습니다. Auto-sklearn은 scikit-learn 기반으로 개발된 오토ML 도구로, <strong>베이지안 최적화</strong>를 통해 다양한 학습기와 전처리 조합 중 최적 파이프라인을 찾아냅니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Introduction%20to%20Auto">[33]</a>. 특징적인 것은 메타러닝을 도입했다는 점인데, 수백 개의 공개 데이터셋에 대해 어떤 모델구성이 좋은 성능을 냈는지 <strong>메타-데이터베이스</strong>를 만들어 두고, 새로운 데이터에 Auto-sklearn을 돌리면 그 메타정보를 참고하여 <strong>초기 후보군을 똑똑하게 선택</strong>합니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=A%20second%20method%20used%20by,and%20to%20optimize%20calculation%20time">[34]</a>. 이를 통해 쓸모없을 것이 뻔한 모델 유형이나 하이퍼파라미터 조합은 애초에 시도하지 않음으로써 <strong>탐색 시간을 절약</strong>하고, 적은 시도로도 우수한 결과를 얻을 확률을 높입니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Auto,is%20very%20expensive%20to%20calculate">[35]</a>. Auto-sklearn은 또한 최종적으로 여러 상위 모델을 <strong>앙상블</strong>하여 안정적 성능을 내는 기능도 갖추고 있어, 2015년 NIPS AutoML 챌린지 등에서 좋은 성적을 거둔 바 있습니다.</p>
<p>또 다른 도구 <strong>TPOT(Tree-based Pipeline Optimization Tool)</strong>는 <strong>유전 알고리즘</strong>을 이용하여 파이프라인을 최적화합니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=TPOT%20%28Tree,the%20best%20individuals%20are%20retained">[36]</a>. TPOT은 데이터 전처리(예: 스케일링, PCA)부터 모델(예: 결정트리, SVM, XGBoost)까지 일련의 단계들을 하나의 <strong>유전자(sequence)</strong>로 표현하고, 진화 알고리즘의 돌연변이와 교차를 통해 세대를 거듭하며 최적 파이프라인을 “진화”시킵니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=TPOT%20%28Tree,the%20best%20individuals%20are%20retained">[36]</a>. 초기에는 무작위 파이프라인 집합으로 시작해 반복마다 성능이 나쁜 파이프라인은 도태시키고, 우수한 파이프라인을 변이·교배하여 새로운 후보를 만들면서 탐색합니다. TPOT의 장점은 <strong>다양한 비선형 조합을 시도</strong>해볼 수 있다는 것이며, 최종적으로 발견된 최적 파이프라인을 <strong>파이썬 코드로까지 자동 생성</strong>해주기 때문에 사용자가 그대로 활용할 수 있습니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=TPOT%20supports%20a%20wide%20variety,and%20train%20the%20ML%20model">[37]</a>. 다만 유전 알고리즘 특성상 반복 실행마다 결과가 달라질 수 있고, 탐색 속도가 베이지안 방법보다는 느릴 수 있다는 trade-off가 있습니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Because%20of%20the%20use%20of,time%20the%20model%20is%20trained">[38]</a>. 그럼에도 TPOT은 사용이 간편하고(<strong>라인 몇 줄의 코드</strong>로 AutoML 수행), 비교적 <strong>짧은 시간에 그럴듯한 모델을 얻기 쉬워</strong> 초보자들에게 인기가 높습니다<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=As%20seen%20above%2C%20TPOT%20is,it%20doesn%27t%20require%20programming%20knowledge">[39]</a>.</p>
<p><strong>H2O AutoML</strong>도 빼놓을 수 없습니다. H2O.ai에서 개발한 오토ML 스위트로, 여러 가지 머신러닝 알고리즘(예: XGBoost, GLM, RandomForest 등)을 <strong>정해진 시간 내에 병렬로 모두 학습</strong>시키고, 그 중 상위 모델들을 <strong>스태킹 앙상블</strong>하여 최종 모델을 만들어내는 방식입니다<a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a>. H2O AutoML의 특징은 별도의 복잡한 설정 없이 <strong>주어진 시간 동안 최선을 다해 탐색</strong>한다는 점과, 내부적으로 <strong>과거 시도들의 결과(메타러닝)도 활용</strong>하여 점진적으로 성능을 올린다는 점입니다<a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a>. 특히 H2O는 <strong>모델간 블렌딩과 스태킹</strong>을 자동화하여 단일 모델보다 일관적이고 높은 예측 성능을 확보하는 데 강점이 있습니다<a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a>. 이러한 기능으로 H2O AutoML은 캐글(Kaggle) 등 데이터 사이언스 현업에서 실용적으로 많이 쓰이고 있으며, R이나 파이썬에서 간단히 함수 호출만으로 사용할 수 있어 편의성도 높습니다.</p>
<p>이밖에도 <strong>Auto-Keras</strong>(딥러닝 모델 전용 AutoML), <strong>Auto-PyTorch</strong>, <strong>AutoGluon</strong>, <strong>MLBox</strong> 등 다양한 오토ML 툴킷들이 연구 및 배포되고 있습니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=workflows%20%28Hutter%20et%C2%A0al,complex%20configuration%20interfaces%2C%20understand%20technical">[41]</a><a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a>. 이들 각각은 저마다의 탐색 전략(예: Auto-Keras는 신경망 블록 조합 탐색, AutoGluon은 견고한 앙상블 등)과 강점을 가지지만, 공통적으로 <strong>파이프라인 구성 요소의 자동화</strong>라는 큰 목표 아래 발전하고 있습니다. <strong>메타러닝</strong>은 이러한 파이프라인 자동화에서 핵심 개념으로, AutoML 시스템이 <strong>“어떤 데이터셋에는 어떤 접근이 좋았다”</strong>는 경험을 축적함으로써 <strong>시간이 지남에 따라 똑똑해지는</strong> 효과를 내고 있습니다<a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a>. 이는 AutoML이 단순한 brute-force 자동화가 아니라 <strong>학습하는 AutoML</strong>로 진화하고 있음을 보여줍니다.</p>
<h2 id="automl-">AutoML 연구의 핵심 개념: 탐색 공간, 탐색 알고리즘, 성능 추정 전략</h2>
<p><em>AutoML 워크플로우: 데이터 준비, 특징 공학(모델 엔지니어링), 모델 생성(탐색 공간 및 최적화 방법), 모델 평가(저비용 성능 추정 기법)까지 다양한 자동화 단계로 구성된다</em><a href="https://commons.wikimedia.org/wiki/File:AutoML_diagram.png#:~:text=English%3A%20%20This%20Figure%20illustrates,Model%20Generation%2C%20and%20Model%20Evaluation"><em>[42]</em></a><em>.</em> AutoML 방법론을 이해하기 위해서는 <strong>세 가지 핵심 개념</strong>을 짚고 넘어갈 필요가 있습니다. 첫째는 <strong>탐색 공간(Search Space)</strong>의 정의이고, 둘째는 그 공간을 탐색하는 <strong>탐색 알고리즘(Search Strategy)</strong>이며, 셋째는 후보의 우열을 가리는 <strong>성능 추정 전략(Performance Estimation)</strong>입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[43]</a>. 이 개념들은 앞서 소개한 각 연구 흐름(예: NAS, HPO, 등)에서 공통적으로 나타나는 중요한 요소입니다.</p>
<ul>
<li><strong>탐색 공간 정의</strong>: 자동화 과정에서 고려하는 <strong>설정들의 집합</strong>을 의미합니다. 예를 들어 HPO에서는 탐색 공간이 학습률, 나무 깊이 등 <strong>튜닝 대상 하이퍼파라미터의 범위</strong>가 될 것이고, NAS에서는 <strong>신경망 레이어 조합과 연결 구조들</strong>이 탐색 공간을 이룹니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[44]</a>. 파이프라인 최적화의 경우 전처리 기법, 알고리즘 종류, 하이퍼파라미터 등이 모두 탐색 공간에 포함됩니다. 탐색 공간을 어떻게 설계하느냐에 따라 AutoML의 효율성과 성능이 크게 좌우되는데, <strong>공간을 너무 넓게 잡으면</strong> 불필요한 조합을 많이 검사하게 되어 비효율적이고, <strong>너무 좁게 잡으면</strong> 최적 솔루션을 놓칠 위험이 있습니다. 따라서 도메인 지식이나 선행 연구를 바탕으로 <strong>적절한 제약을 둔 탐색 공간</strong>을 설정하는 것이 중요합니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%97%B0%EA%B2%B0%EA%B5%AC%EC%A1%B0%EC%99%80%20%EA%B0%80%EC%A4%91%EC%B9%98%EB%A5%BC%20%ED%83%90%EC%83%89%20%EB%8C%80%EC%83%81%EC%9C%BC%EB%A1%9C%20%EC%82%BC%EB%8A%94%EB%8B%A4,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[45]</a>. 예를 들어 NAS에서는 <strong>모듈화된 셀 구조</strong>를 기본 단위로 탐색 공간을 한정하거나, HPO에서 <strong>로그 스케일</strong>로 범위를 설정하는 등이 효과적인 설계로 알려져 있습니다. 탐색 공간 설계는 AutoML 연구자에게 여전히 까다로운 문제로, <strong>검색 영역을 재설계하거나 축소</strong>하여 효율을 높이는 연구가 최근에도 이어지고 있습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%98%90%ED%95%9C%2C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,30%5D%20%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C%20%EC%A0%95%ED%99%95%EB%8F%84%20%EB%8C%80%EB%B9%84">[10]</a>.</li>
<li><strong>탐색 알고리즘</strong>: 정의된 탐색 공간에서 <strong>어떤 순서와 방법으로 후보들을 선택하고 개선해나갈지</strong>를 결정하는 전략입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[43]</a>. 간단한 예로 랜덤 탐색은 탐색 알고리즘이 무작위 추출에 불과하지만, 베이지안 최적화는 <strong>획득함수 기반으로 다음 후보를 영리하게 선택</strong>하는 알고리즘입니다. NAS에서는 진화 알고리즘, 강화학습, 미분기법 등이 탐색 알고리즘으로 쓰일 수 있고<a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=%2A%20Reinforcement%20Learning,move%20forward%20in%20the%20search">[46]</a>, 파이프라인 최적화에선 유전 알고리즘(TPOT)이나 Bayesian + 메타러닝(auto-sklearn) 등이 쓰입니다. 탐색 알고리즘의 목표는 <strong>적은 시도로 우수한 솔루션을 찾아내는 것</strong>입니다. 따라서 글로벌 탐색(exploration)과 로컬 세밀 탐색(exploitation)의 균형을 맞추는 것이 중요하며, 전자는 새로운 영역을 개척해 최적점을 찾도록 하고 후자는 현재 좋은 솔루션 주변을 파고들어 미세 튜닝하는 역할을 합니다<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=low,0">[47]</a>. 현대 AutoML 연구에서는 이 균형을 위한 기법들 – 예를 들어 <strong>MCTS(몬테카를로 트리 탐색)</strong>, <strong>밴디트 알고리즘</strong>, <strong>PBT</strong> – 등을 도입하기도 합니다. 또한 탐색 알고리즘의 효율을 높이기 위해 <strong>병렬화</strong>나 <strong>분산 처리</strong>를 사용하는 것도 실용상 중요합니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4%20%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[21]</a>.</li>
<li><strong>성능 추정 전략</strong>: 후보 솔루션(예: 특정 하이퍼파라미터 조합이나 네트워크 구조)의 <strong>품질을 얼마나 빨리 정확히 가늠할 것인가</strong>의 문제입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[43]</a>. 모든 후보를 <strong>완전한 학습으로 평가</strong>할 수 있다면 이상적이겠지만, 현실적으로 시간과 자원이 제약되므로 <strong>빠르고 거친 평가 방법</strong>이 필수적입니다. 가장 기본은 <strong>검증 데이터셋을 활용한 정확도 평가</strong>이지만, 이 역시 학습을 다 해야 나오는 값이므로 비용이 큽니다. 이를 개선하는 대표적인 전략이 앞서 언급한 <strong>멀티-피델리티 평가</strong>입니다. 예를 들어 Hyperband에서는 <strong>짧은 시간(또는 작은 데이터)</strong> 학습으로 1차 평가하고, 상위 후보만 선별해 <strong>더 긴 시간</strong> 학습하여 재평가하는 식으로 <strong>계단식 평가</strong>를 진행했습니다<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=match%20at%20L2112%20A%20popular,performing%20ones%20early">[16]</a>. 이처럼 <strong>학습 예산을 점증적으로 늘리면서</strong> 유망도를 추리는 방식은 NAS에도 적용되어, <strong>점진적으로 에폭을 늘려가며 구조를 평가</strong>하거나 하는 기법들이 사용됩니다. 또 다른 접근은 <strong>엔삼블링을 통한 추정</strong>으로, 여러 작은 모델들의 결과를 합쳐서 대략의 성능을 가늠하거나, <strong>교차검증 결과를 누적</strong>하여 신뢰구간을 추정하는 방법도 있습니다.</li>
</ul>
<p>최근 들어 각광받는 혁신적 방법은 <strong>Zero-Cost Proxy</strong>라는 개념입니다. 이는 아예 <strong>모델을 풀로 학습시키지 않고도</strong> 해당 모델의 잠재 성능을 예측해보는 기법들입니다<a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=This%20is%20where%20zero,architecture%20without%20fully%20training%20it">[48]</a>. 예를 들어 <strong>SynFlow</strong>, <strong>NASWOT</strong>, <strong>GradNorm</strong> 등의 지표들은 신경망의 <strong>초기 가중치와 구조만 가지고</strong> 그 네트워크가 얼마나 복잡한 패턴을 학습할 수 있을지 점수화합니다. Mellor 등(2020)의 선구적 연구에서는 초기 가중치로 랜덤 초기화된 네트워크에 입력을 넣었을 때 <strong>특정 활성화 패턴을 보이는 정도</strong>로 성능을 예측하는 기법을 제안했고, 이후 여러 zero-cost 프록시들이 개발되었습니다<a href="https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/#:~:text=Zero,The%20method">[49]</a>. 이러한 지표들은 <strong>신경망을 한 번도 학습시키지 않고도</strong> 구조의 상대적 우열을 빠르게 평가해주므로, 나쁜 후보를 초기에 걸러내 탐색 효율을 극대화할 수 있습니다<a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=This%20is%20where%20zero,architecture%20without%20fully%20training%20it">[48]</a><a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Similarly%2C%20zero,skipping%20the%20costly%20training%20phase">[50]</a>. 비유하자면 집을 다 지어보지 않고도 <strong>기초 공사만 보고 집의 완성 퀄리티를 예측</strong>하는 셈입니다<a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Define%20Zero">[51]</a>. 아직 완벽하진 않지만 계속 개선되고 있으며, NAS 등에서 실제 <strong>탐색 방향을 안내하는 성능 예측자로 활용</strong>되고 있습니다<a href="https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/#:~:text=Zero,The%20method">[49]</a><a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Yadav%20medium.com%20%20Zero,skipping%20the%20costly%20training%20phase">[52]</a>.</p>
<p>정리하면, AutoML의 모든 방법론은 <strong>탐색 공간을 어떻게 정의하고, 어떤 알고리즘으로 탐색하며, 어느 정도 비용으로 성능을 가늠할 것인가</strong>라는 공통된 도전에 직면해 있습니다. 각 연구마다 이 세 축을 조합하는 방식을 달리하며 효율성과 효과를 높이고자 노력해왔습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[43]</a>. 다음 장에서는 이러한 개념들이 최근 AutoML 연구에서 어떤 방향으로 발전하고 있는지, 최신 동향을 살펴보겠습니다.</p>
<h2 id="-">최근 트렌드 및 발전 방향</h2>
<p>AutoML 분야는 빠르게 진화하고 있으며, 최근에는 <strong>효율성 제고</strong>와 <strong>적용 범위 확장</strong>을 위한 다양한 시도가 이루어지고 있습니다. 특히 멀티-피델리티 및 제로-코스트 방법, NAS의 효율화, 대규모 언어모델(LLM)과의 접목, 그리고 산업계 응용 및 클라우드 서비스화 등이 두드러진 흐름입니다.</p>
<h3 id="multi-fidelity-zero-cost-proxy-">Multi-fidelity 및 Zero-cost Proxy 기법</h3>
<p><strong>탐색 효율을 극대화</strong>하기 위한 방법으로 멀티-피델리티(Multi-fidelity) 최적화와 제로-코스트 프록시가 활발히 연구되고 있습니다. 멀티-피델리티 기법은 앞서 설명한 Hyperband처럼 <strong>부분적인 리소스로 빠르게 후보를 평가</strong>한 뒤 점진적으로 정밀도를 높이는 접근입니다<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=match%20at%20L2112%20A%20popular,performing%20ones%20early">[16]</a>. 최근에는 이 아이디어를 발전시켜, 예를 들어 <strong>학습 에폭을 몇 단계로 나누어</strong> 각 단계마다 성능이 나쁜 모델을 잘라내는 <strong>동적 자원 할당</strong> 기법이나, <strong>데이터 샘플의 크기를 점증</strong>시키며 튜닝하는 방법 등이 나왔습니다. 또한 Hyperband와 베이지안 최적화를 결합한 BOHB 외에도, <strong>Freeze-Thaw BO</strong>(학습 곡선을 예측해 조기중단 결정)나 <strong>ASHA(Asynchronous Successive Halving)</strong> 등 여러 변종들이 제안되어 분산 환경에서의 효율적 HPO를 구현하고 있습니다. 이들 방법은 공통적으로 <strong>“적은 비용으로 대략 걸러내고, 좋은 놈에게만 충분한 자원을”</strong>이라는 원칙 아래 동작하여, <strong>탐색 시간을 기존 대비 수배 이상 단축</strong>하는 효과를 보입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4%20%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[21]</a>.</p>
<p><strong>Zero-cost proxy</strong>는 앞서 언급한 대로 <strong>사전 학습 없이 모델 성능을 예측</strong>하는 파격적인 방법입니다. 최근 NAS 연구에서 특히 주목받고 있는데, 대표 지표인 <strong>NASWOT</strong>(Without Training)을 비롯해 <strong>SynFlow</strong>, <strong>Fisher</strong>, <strong>GradSign</strong> 등 여러 제로코스트 점수들이 개발되었습니다<a href="https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/#:~:text=Zero,The%20method">[49]</a><a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Yadav%20medium.com%20%20Zero,skipping%20the%20costly%20training%20phase">[52]</a>. 예컨대 SynFlow는 신경망의 <strong>연결 가중치 흐름을 분석</strong>하여 <strong>값이 0으로 소멸되지 않는 경로 수</strong>를 세어 구조의 표현력을 평가하고, NASWOT은 <strong>랜덤 가중치로 초기화된 신경망의 출력 다변성</strong>(output variance)을 측정합니다. 이러한 프록시들은 일반적으로 <strong>계산 몇 번</strong>으로 얻을 수 있어 비용이 무시할 수준으로 적습니다. 물론 절대적인 예측 정확도는 높지 않지만, <strong>순위 상관관계</strong> 측면에서 어느 정도 유용성을 보여주고 있어, NAS에서 <strong>초기 탐색 방향을 안내</strong>하거나 HPO에서 <strong>초벌 필터</strong>로 활용되고 있습니다<a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=This%20is%20where%20zero,architecture%20without%20fully%20training%20it">[48]</a><a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Similarly%2C%20zero,skipping%20the%20costly%20training%20phase">[50]</a>. 최근에는 여러 프록시 지표를 <strong>앙상블하여 정확도를 높이는 연구</strong><a href="https://arxiv.org/html/2505.09344v1#:~:text=...%20arxiv.org%20%20Zero,recent%20proxies%20often%20lack">[53]</a>, <strong>프록시 자체를 학습으로 진화시키는 연구(EZNAS)</strong> 등도 진행되며 이 분야가 빠르게 발전하고 있습니다.</p>
<h3 id="nas-">NAS 효율화 및 통합 추구</h3>
<p>신경망 아키텍처 검색(NAS) 분야는 여전히 AutoML의 핵심 연구주제로, <strong>탐색 비용을 줄이고 실용성을 높이는 방향</strong>으로 진화하고 있습니다. 앞서 살펴본 ENAS의 <strong>파라미터 공유</strong>나 DARTS의 <strong>연속 공간 Relaxation</strong>은 NAS 효율화를 크게 이끈 기법들입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5%20%EA%B8%B0%EB%B0%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98,%EC%9E%AC%ED%99%9C%EC%9A%A9%EC%9D%B4%20%EC%97%86%EC%96%B4%20%EA%B3%84%EC%82%B0%20%EB%B3%B5%EC%9E%A1%EB%8F%84%20%EB%AC%B8%EC%A0%9C%EC%97%90">[6]</a><a href="https://arxiv.org/abs/1806.09055#:~:text=,differentiable%20techniques">[7]</a>. 여기에 더해 최근에는 <strong>One-shot NAS</strong>와 <strong>Weight-sharing Supernet</strong> 기법이 각광받았습니다. One-shot NAS는 하나의 거대 신경망(Supernet)에 모든 후보 구조를 포함시켜놓고 학습한 후, 그 <strong>부분망을 샘플링</strong>하여 평가하는 방법으로, ENAS와 유사하게 <strong>모든 후보가 학습된 가중치를 일부라도 공유</strong>하므로 탐색 속도를 비약적으로 개선합니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%A7%84%ED%99%94%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EB%B0%8F%20%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5,25">[54]</a>. 이는 2019년구글 Brain과 CMU 등이 선보인 기법으로, 수천 GPU 시간에 달하던 NAS를 수십 GPU 시간으로 단축시켜 <strong>NAS의 실용화 문턱을 낮추었습니다</strong>.</p>
<p>또한 NAS 연구자들은 <strong>검색 공간 자체를 영리하게 설계</strong>하여 효율을 높이고 있습니다. 예컨대 모바일 기기를 위한 NAS에서는 <strong>연산자 종류를 제한</strong>하고 <strong>모델 크기 제약</strong>을 넣어 불필요하게 거대한 구조는 애초에 배제하거나, <strong>모듈러 셀 구조</strong>를 활용해 탐색 차원을 줄이는 식입니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%98%90%ED%95%9C%2C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,30%5D%20%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C%20%EC%A0%95%ED%99%95%EB%8F%84%20%EB%8C%80%EB%B9%84">[10]</a>. 이렇게 하면 탐색 복잡도가 감소할 뿐 아니라, <strong>발견된 구조를 다른 문제에 전이(transfer)</strong>하기도 용이해집니다. 실제로 NASNet에서 제안된 <strong>셀 구조</strong>는 이후 다양한 NAS 연구의 기본 단위로 활용되었고, 이를 통해 <strong>ImageNet 같은 대형 데이터셋에도 NAS를 직접 적용</strong>하는 성과를 냈습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%98%90%ED%95%9C%2C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,30%5D%20%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C%20%EC%A0%95%ED%99%95%EB%8F%84%20%EB%8C%80%EB%B9%84">[10]</a>. 최근에는 <strong>모델 경량화(quantization, pruning)</strong> 기법과 NAS를 결합하거나, <strong>멀티-목적 NAS</strong>(정확도와 모델 크기/지연시간 등을 동시에 최적화) 등 통합적 접근도 시도되고 있습니다. 예를 들어 MnasNet(Tan et al., 2019)은 <strong>모델의 모바일 CPU 지연시간</strong>을 함께 고려하는 NAS를 수행하여, 실용적인 수준의 경량 모델을 자동으로 찾아냈습니다. 이처럼 NAS는 <strong>효율성(Efficiency)</strong>뿐 아니라 <strong>현실 제약 통합(Integration)</strong> 측면에서 발전하고 있으며, 향후에는 <strong>HPO와 NAS를 동시에 수행하는 통합 AutoML</strong>이 중요한 방향으로 주목받고 있습니다<a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%97%B0%EA%B5%AC%EB%93%A4%EC%9D%B4%20%EC%A0%9C%EC%95%88%EB%90%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4,%ED%92%80%EA%B3%A0%EC%9E%90%20%ED%95%98%EB%8A%94%20%EC%97%B0%EA%B5%AC%EB%93%A4%EB%8F%84%20%EC%B6%9C%ED%98%84%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[25]</a>. 실제로 Auto-PyTorch나 최근 AutoML 논문들에서는 <strong>하이퍼파라미터와 아키텍처를 하나의 최적화 문제</strong>로 다루어 <strong>진정한 end-to-end 자동화</strong>를 추구하고 있습니다.</p>
<h3 id="llm-automl-">LLM 기반 AutoML 자동화 및 파이프라인 생성</h3>
<p>2023년 이후 눈에 띄는 트렌드는 대규모 언어 모델(LLM; 예: GPT-4)의 등장으로 <strong>자연어 인터페이스 기반 AutoML</strong>이 현실화되고 있다는 점입니다. 전통적인 AutoML 시스템은 여전히 사용자가 <strong>GUI 설정</strong>이나 <strong>약간의 스크립팅</strong>을 통해 구성해야 하는 부분이 있었지만<a href="https://arxiv.org/html/2507.05962v1#:~:text=2020%20%29%2C%20and%20Auto,limitation%20means%20that%20even%20AutoML">[55]</a>, 이제는 <strong>사용자의 자연어 명령만으로</strong> 데이터 준비부터 모델 훈련까지 진행하는 연구가 나타났습니다. 예를 들어 <strong>AutoML-GPT</strong>라는 실험적 시스템은 사용자가 “이런 이런 데이터로 저런 문제를 풀고 싶다”라고 <strong>평문으로 지시하면</strong>, LLM이 그 요구를 해석해 적절한 <strong>데이터 전처리, 모델 선택, 하이퍼파라미터 설정, 학습 코드 작성</strong>까지 자동으로 수행해줍니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=explored%20the%20integration%20of%20LLMs,focused%20mainly%20on%20technical%20automation">[56]</a>. 즉, LLM이 <strong>머신러닝 파이프라인을 생성</strong>하고 제어하는 역할을 하는 것입니다. 이는 일종의 <strong>자연어에서 AutoML로의 컴파일러</strong>가 등장한 셈입니다.</p>
<p>최근 한 연구에서는 이러한 LLM 기반 AutoML 인터페이스를 통해 <strong>비전문가 사용자들도 93% 이상에서 더 높은 정확도를 달성</strong>했고, <strong>개발 시간은 절반 이하로 단축</strong>되는 등 큰 개선을 보였다고 보고했습니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=in%20implementing%20deep%20learning%20solutions,that%20natural%20language%20interfaces%20can">[57]</a>. 자연어 인터페이스가 <strong>기술 장벽을 크게 낮춰주어</strong> ML 구현 성공률을 높이고, 사용자 만족도 역시 높았다는 분석입니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=in%20implementing%20deep%20learning%20solutions,that%20natural%20language%20interfaces%20can">[57]</a>. 예를 들어, 전통적 AutoML 툴을 쓸 때는 사용자가 “분류 문제”, “정규화” 등의 용어를 알아야 했지만, LLM 기반 시스템에서는 “고객 이탈을 예측해줘”와 같은 <strong>일상 언어</strong>로 지시할 수 있고 시스템이 이를 이해해 적절한 솔루션을 찾습니다. 다만 아직은 한계도 있습니다. AutoML-GPT 사례에서 보고된 바에 따르면, 사용자가 <strong>모델 선택, 평가 지표</strong> 등의 개념을 전혀 모르면 완전히 제로코드로 쓰긴 어렵고<a href="https://arxiv.org/html/2507.05962v1#:~:text=still%20has%20significant%20limitations,to%20use%20the%20system%20effectively">[58]</a>, 기본적인 ML 용어는 알고 있어야 하는 현실적인 제한이 있습니다. 그러나 이런 방향의 연구가 활발해지면서, 장차 <strong>음성 또는 텍스트 대화로 ML 모델을 만들어내는</strong> 진정한 AutoML 비서가 등장할 가능성도 보입니다.</p>
<p>또한 LLM을 활용한 또 다른 방향은, LLM 자체를 <strong>Optimizer</strong>로 활용하는 것입니다. 예를 들어 <strong>강화학습+LLM 하이브리드</strong>로서, LLM이 현재까지의 실험 로그를 읽고 <strong>다음 실험을 어떻게 할지 조언</strong>해주는 형태입니다. 이는 일종의 <strong>휴리스틱 보조</strong>로 작용하여, AutoML 탐색을 인간 전문가처럼 인도해줄 수도 있습니다. Microsoft 등에서는 이미 대형 모델을 활용해 <strong>자동으로 피처 추출 코드나 모델 코드를 생성</strong>하고, 이를 곧바로 실행하여 결과를 피드백받는 <strong>시스템 개발</strong>을 진행 중입니다. 이러한 시도는 AutoML을 넘어 <strong>자동 데이터 과학</strong>(Automated Data Science)이라는 흐름과 맞닿아 있으며, 궁극적으로 AI가 AI 개발을 돕는 <strong>자기증진적(auto-catalytic) 시스템</strong>으로 이어질 전망입니다.</p>
<h3 id="-automl-">산업 적용 사례 및 클라우드 기반 AutoML 플랫폼</h3>
<p>AutoML 기술은 연구실을 넘어 산업 현장에서도 빠르게 도입되고 있습니다. <strong>구글, 아마존, MS, H2O.ai</strong> 등에서 상용 AutoML 플랫폼을 출시하여, 개발자나 기업이 손쉽게 활용할 수 있도록 한 지 이미 몇 년 되었습니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=workflows%20%28Hutter%20et%C2%A0al,complex%20configuration%20interfaces%2C%20understand%20technical">[41]</a>. 예를 들어 <strong>Google Cloud AutoML</strong>은 비전(이미지 분류/검출), NLP(번역, 텍스트 분류), 테이블(표 형식 데이터 예측) 등 여러 도메인에 특화된 AutoML 서비스를 제공합니다. 이를 통해 사용자들은 모델링 전문지식이 없어도 <strong>클라우드 상에서 데이터 업로드 -&gt; 자동 모델 학습 -&gt; 배포</strong>의 <strong>엔드투엔드 ML 파이프라인</strong>을 수행할 수 있습니다<a href="https://medium.com/googledeveloperseurope/make-your-life-easier-with-automl-tables-on-google-cloud-8a745c4e7f67#:~:text=So%2C%20I%20suggested%20him%20to,results%20ready%20the%20next%20morning">[30]</a>. <strong>Amazon SageMaker Autopilot</strong> 역시 tabular 데이터에 대해 자동으로 전처리, 알고리즘 선택, 하이퍼파라미터 튜닝을 해주는 서비스를 제공하며, 특히 <strong>두 가지 모드</strong>(다양한 알고리즘 빠르게 시도하는 모드 vs. 특정 알고리즘 정밀 튜닝 모드)를 지원하여 사용자의 요구에 맞게 AutoML을 적용할 수 있습니다<a href="https://medium.com/@bibhushabibhs/aws-automl-no-code-machine-learning-in-amazon-sagemaker-autopilot-f5d7e0be4e6a#:~:text=AWS%20AutoML%20%E2%80%94%20No%20Code,Hyper%20Parameter">[59][59]</a>. 이러한 클라우드 AutoML 서비스들은 <strong>대용량 데이터</strong>도 분산 인프라에서 병렬 처리해주므로, 사용자는 인프라 구성이나 병렬화에 신경쓸 필요 없이 <strong>확장성 있는 AutoML</strong>을 활용할 수 있습니다.</p>
<p>산업계 활용 사례로는 <strong>금융</strong>에서 AutoML을 이용해 <strong>사기 거래 탐지 모델</strong>을 만들거나, <strong>마케팅</strong> 부서에서 고객 이탈 예측 모델을 AutoML로 구축하는 경우가 흔해지고 있습니다<a href="https://cloud.google.com/blog/products/ai-machine-learning/new-automl-features-and-end-to-end-workflows-on-ai-platform-pipelines#:~:text=AutoML%20Tables%20%20lets%20you,46%2C%20and%20more">[29]</a>. <strong>의료 분야</strong>에서도 AutoML로 빠르게 예측 모델을 만들어 전염병 유행 예측이나 환자 재입원 예측 등에 활용하는 사례가 보고됩니다. 한 연구에 따르면, AutoML 도구를 활용한 그룹이 수작업 모델링한 그룹보다 <strong>일관되게 높은 정확도와 더 빠른 개발주기</strong>를 보였다고 합니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=in%20implementing%20deep%20learning%20solutions,that%20natural%20language%20interfaces%20can">[57]</a>. 이는 AutoML이 가져올 <strong>생산성 혁신</strong>을 보여주는 예로, 특히 데이터 사이언티스트 인력이 부족한 중소 조직이나, <strong>데이터는 많은데 해석 인력이 부족한 기업</strong>에서 AutoML에 대한 수요가 높습니다.</p>
<p>주요 클라우드 플랫폼들은 AutoML 서비스를 계속 진화시키고 있습니다. 구글은 AutoML을 자사의 <strong>Vertex AI 플랫폼</strong>에 통합하여 UI/SDK를 개선하고 있고, <strong>Azure</strong>도 자체 AutoML 기능을 머신러닝 스튜디오에 포함하고 있습니다<a href="https://arxiv.org/html/2507.05962v1#:~:text=workflows%20%28Hutter%20et%C2%A0al,complex%20configuration%20interfaces%2C%20understand%20technical">[41]</a>. H2O.ai의 <strong>Driverless AI</strong>는 AutoML을 넘어 <strong>자동 보고서 생성, 모델 설명(Explainability)</strong> 기능까지 제공하여 기업 현장에서 유용하게 쓰입니다. 이들 솔루션들은 대체로 <strong>사람 전문가의 작업 흐름</strong>(Feature Engineering -&gt; Modeling -&gt; Tuning -&gt; Ensembling -&gt; Deployment)을 모사하면서도, 반복적 작업을 자동화하고 최적화를 가속화하는 방향으로 발전 중입니다.</p>
<p>마지막으로, AutoML의 산업 적용에서 중요한 이슈는 <strong>모델 해석성과 신뢰성</strong>입니다. 자동으로 만들어진 모델이라 해도 비즈니스 현장에선 <strong>왜 그런 예측이 나왔는지</strong> 설명할 수 있어야 하기 때문입니다. 이에 따라 AutoML 플랫폼들은 <strong>모델 설명 기법(SHAP, LIME 등)을 자동 적용</strong>해주거나, <strong>fairness(공정성) 지표</strong>를 함께 리포팅하는 등 책임있는 AI 활용을 지원하고 있습니다. 예컨대 Google AutoML Tables는 최종 모델에 대해 <strong>특성 중요도(feature importance)</strong>를 제공하고, AWS Autopilot은 <strong>모델 설명 보고서</strong>를 자동 생성해 줍니다<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html#:~:text=After%20the%20experiment%20runs%2C%20you,or%20the%20candidate%20model%20definitions">[60]</a><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html#:~:text=">[61]</a>. 이는 AutoML이 <strong>현업 표준</strong>으로 자리잡기 위해 풀어야 할 과제이기도 합니다.</p>
<h2 id="-">맺음말</h2>
<p>AutoML은 <strong>“AI를 만드는 AI”</strong>로 불리며 머신러닝 분야의 지평을 넓혀왔습니다. 초기에는 학계의 흥미로운 연구 주제로 출발했지만, 이제는 다양한 <strong>오픈소스 라이브러리와 클라우드 서비스</strong>로 구현되어 <strong>실제 문제 해결에 공헌</strong>하고 있습니다. AutoML의 발전으로 머신러닝 모델링의 <strong>진입장벽은 낮아지고</strong>, 숙련된 연구자들도 반복적 튜닝 작업에서 해방되어 더 창의적인 문제에 집중할 수 있게 되었습니다.</p>
<p>물론 해결해야 할 문제도 남아 있습니다. 자동으로 생성된 모델의 <strong>신뢰성</strong>과 <strong>윤리적 검증</strong>, AutoML 프로세스의 <strong>데이터 효율성</strong>(적은 데이터로도 잘 작동하는지), 그리고 AutoML 시스템 간의 <strong>표준화</strong> 등이 그것입니다. 하지만 학계와 업계 모두 AutoML의 가치를 인정하고 있어, 앞으로도 <strong>사람과 AI가 협업</strong>하여 더 나은 모델을 빠르게 만드는 기술들이 속속 등장할 것으로 기대됩니다. <strong>AI 연구자</strong>라면 AutoML의 개념과 흐름을 폭넓게 이해하고, 이를 활용하거나 개선하는 방향으로 나아가는 것이 중요합니다. AutoML은 <strong>머신러닝 실무의 민주화</strong>를 이끌 뿐 아니라, 궁극적으로 <strong>AI 연구의 자동화</strong>라는 도전적인 목표를 향해 진화하고 있습니다. 변화의 속도가 빠른 만큼 최신 동향에 관심을 갖고 지켜볼 필요가 있으며, 오늘 소개한 내용이 AutoML 분야에 대한 폭넓은 이해에 도움이 되었기를 바랍니다.</p>
<p><strong>참고 문헌:</strong> AutoML 개념 및 기술 동향<a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=an%20artificial%20intelligence,designed%20models.%5B%204">[3]</a><a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=data%20points%20to%20be%20used,by%20the%20machine%20learning%20expert">[1]</a><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[43]</a>, NAS 분야 연구<a href="https://arxiv.org/abs/1611.01578#:~:text=understanding,the%20Penn%20Treebank%20dataset%2C%20our">[5]</a><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5%20%EA%B8%B0%EB%B0%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98,%EC%9E%AC%ED%99%9C%EC%9A%A9%EC%9D%B4%20%EC%97%86%EC%96%B4%20%EA%B3%84%EC%82%B0%20%EB%B3%B5%EC%9E%A1%EB%8F%84%20%EB%AC%B8%EC%A0%9C%EC%97%90">[6]</a><a href="https://arxiv.org/abs/1806.09055#:~:text=,differentiable%20techniques">[7]</a>, HPO 기법 발전<a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=match%20at%20L2112%20A%20popular,performing%20ones%20early">[16]</a><a href="https://arxiv.org/abs/1807.01774#:~:text=configurations%20as%20quickly,the%20same%20time%20being%20conceptually">[23]</a>, 특징 공학 자동화 사례<a href="https://arxiv.org/abs/1901.07329#:~:text=feature%20engineering%20and%20selection%20capabilities,meaningful%20features%20is%20selected%2C%20which">[26]</a><a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf#:~:text=II,explain%20the%20motivation%20for%20Deep">[27]</a>, 파이프라인 AutoML 도구<a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Auto,is%20very%20expensive%20to%20calculate">[35]</a><a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a>, LLM 접목 AutoML 전망<a href="https://arxiv.org/html/2507.05962v1#:~:text=explored%20the%20integration%20of%20LLMs,focused%20mainly%20on%20technical%20automation">[56]</a><a href="https://arxiv.org/html/2507.05962v1#:~:text=in%20implementing%20deep%20learning%20solutions,that%20natural%20language%20interfaces%20can">[57]</a>, AutoML 산업 적용<a href="https://arxiv.org/html/2507.05962v1#:~:text=workflows%20%28Hutter%20et%C2%A0al,complex%20configuration%20interfaces%2C%20understand%20technical">[41]</a><a href="https://cloud.google.com/blog/products/ai-machine-learning/new-automl-features-and-end-to-end-workflows-on-ai-platform-pipelines#:~:text=AutoML%20Tables%20%20lets%20you,46%2C%20and%20more">[29]</a> 등.</p>
<p><a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=data%20points%20to%20be%20used,by%20the%20machine%20learning%20expert">[1]</a> <a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=After%20these%20steps%2C%20practitioners%20must,by%20the%20machine%20learning%20expert">[2]</a> <a href="https://en.wikipedia.org/wiki/Automated_machine_learning#:~:text=an%20artificial%20intelligence,designed%20models.%5B%204">[3]</a> Automated machine learning - Wikipedia</p>
<p><a href="https://en.wikipedia.org/wiki/Automated_machine_learning">https://en.wikipedia.org/wiki/Automated_machine_learning</a></p>
<p><a href="https://arxiv.org/html/2507.05962v1#:~:text=accessibility%20challenge%20by%20attempting%20to,2021%29%2C%20and%20platforms%20like">[4]</a> <a href="https://arxiv.org/html/2507.05962v1#:~:text=workflows%20%28Hutter%20et%C2%A0al,complex%20configuration%20interfaces%2C%20understand%20technical">[41]</a> <a href="https://arxiv.org/html/2507.05962v1#:~:text=2020%20%29%2C%20and%20Auto,limitation%20means%20that%20even%20AutoML">[55]</a> <a href="https://arxiv.org/html/2507.05962v1#:~:text=explored%20the%20integration%20of%20LLMs,focused%20mainly%20on%20technical%20automation">[56]</a> <a href="https://arxiv.org/html/2507.05962v1#:~:text=in%20implementing%20deep%20learning%20solutions,that%20natural%20language%20interfaces%20can">[57]</a> <a href="https://arxiv.org/html/2507.05962v1#:~:text=still%20has%20significant%20limitations,to%20use%20the%20system%20effectively">[58]</a> Evaluation of Large Language Model-Driven AutoML in Data and Model Management from Human-Centered Perspective</p>
<p><a href="https://arxiv.org/html/2507.05962v1">https://arxiv.org/html/2507.05962v1</a></p>
<p><a href="https://arxiv.org/abs/1611.01578#:~:text=understanding,the%20Penn%20Treebank%20dataset%2C%20our">[5]</a> [1611.01578] Neural Architecture Search with Reinforcement Learning</p>
<p><a href="https://arxiv.org/abs/1611.01578">https://arxiv.org/abs/1611.01578</a></p>
<p><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5%20%EA%B8%B0%EB%B0%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98,%EC%9E%AC%ED%99%9C%EC%9A%A9%EC%9D%B4%20%EC%97%86%EC%96%B4%20%EA%B3%84%EC%82%B0%20%EB%B3%B5%EC%9E%A1%EB%8F%84%20%EB%AC%B8%EC%A0%9C%EC%97%90">[6]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%98%90%ED%95%9C%2C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,30%5D%20%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C%20%EC%A0%95%ED%99%95%EB%8F%84%20%EB%8C%80%EB%B9%84">[10]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=1">[11]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%98%88%EC%B2%98%EB%9F%BC%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%EA%B5%AC%EA%B0%84%20%EB%82%B4%EC%97%90%EC%84%9C,%EB%B0%9C%EA%B2%AC%ED%95%A0%20%EC%88%98%20%EC%9E%88%EB%8A%94%20%EA%B0%80%EB%8A%A5%EC%84%B1%EC%9D%84%20%EB%86%92%EC%98%80%EB%8B%A4">[12]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=2">[13]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%9C%84%EC%99%80%20%EA%B0%99%EC%9D%80%20%EB%B0%A9%EC%8B%9D%EC%9C%BC%EB%A1%9C%20%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94%20%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88,%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%EC%B5%9C%EC%A0%81%ED%99%94%20%EA%B8%B0%EC%88%A0%EC%9D%B4%20%EB%93%B1%EC%9E%A5%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[14]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=match%20at%20L188%20Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[20]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=Hyperband%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4%20%EB%AC%B4%EC%9E%91%EC%9C%84%EB%A1%9C%20%ED%95%98%EC%9D%B4%ED%8D%BC%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0,%EC%8B%A4%ED%97%98%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%EC%9A%B0%EC%88%98%ED%95%9C%20%EC%84%B1%EB%8A%A5%EC%9D%84%20%EB%B3%B4%EC%98%80%EB%8B%A4">[21]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=BOHB,8%5D%EA%B0%80">[22]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=match%20at%20L364%20%EC%97%B0%EA%B5%AC%EB%93%A4%EC%9D%B4%20%EC%A0%9C%EC%95%88%EB%90%98%EA%B3%A0,%ED%92%80%EA%B3%A0%EC%9E%90%20%ED%95%98%EB%8A%94%20%EC%97%B0%EA%B5%AC%EB%93%A4%EB%8F%84%20%EC%B6%9C%ED%98%84%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[24]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%97%B0%EA%B5%AC%EB%93%A4%EC%9D%B4%20%EC%A0%9C%EC%95%88%EB%90%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4,%ED%92%80%EA%B3%A0%EC%9E%90%20%ED%95%98%EB%8A%94%20%EC%97%B0%EA%B5%AC%EB%93%A4%EB%8F%84%20%EC%B6%9C%ED%98%84%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[25]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[43]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EB%8B%A4%EC%9D%8C%EC%9C%BC%EB%A1%9C%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%83%90%EC%83%89%20%EA%B8%B0%EC%88%A0%EC%9D%80,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[44]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%97%B0%EA%B2%B0%EA%B5%AC%EC%A1%B0%EC%99%80%20%EA%B0%80%EC%A4%91%EC%B9%98%EB%A5%BC%20%ED%83%90%EC%83%89%20%EB%8C%80%EC%83%81%EC%9C%BC%EB%A1%9C%20%EC%82%BC%EB%8A%94%EB%8B%A4,%ED%83%90%EC%83%89%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%B4%88%EC%A0%90%EC%9D%84%20%EB%A7%9E%EC%B6%94%EA%B3%A0%20%EC%9E%88%EB%8B%A4">[45]</a> <a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html#:~:text=%EC%A7%84%ED%99%94%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EB%B0%8F%20%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5,25">[54]</a> 자동 기계학습(AutoML) 기술 동향</p>
<p><a href="https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html">https://ettrends.etri.re.kr/ettrends/178/0905178004/0905178004.html</a></p>
<p><a href="https://arxiv.org/abs/1806.09055#:~:text=,differentiable%20techniques">[7]</a> <a href="https://arxiv.org/abs/1806.09055#:~:text=,for%20language%20modeling%2C%20while%20being">[8]</a> <a href="https://arxiv.org/abs/1806.09055#:~:text=non,differentiable%20techniques">[9]</a> [1806.09055] DARTS: Differentiable Architecture Search</p>
<p><a href="https://arxiv.org/abs/1806.09055">https://arxiv.org/abs/1806.09055</a></p>
<p><a href="https://arxiv.org/abs/1807.01774#:~:text=,consistently%20outperforms%20both%20Bayesian%20optimization">[15]</a> <a href="https://arxiv.org/abs/1807.01774#:~:text=infeasible,forward%20neural%20networks%2C%20Bayesian">[19]</a> <a href="https://arxiv.org/abs/1807.01774#:~:text=configurations%20as%20quickly,the%20same%20time%20being%20conceptually">[23]</a> [1807.01774] BOHB: Robust and Efficient Hyperparameter Optimization at Scale</p>
<p><a href="https://arxiv.org/abs/1807.01774">https://arxiv.org/abs/1807.01774</a></p>
<p><a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=match%20at%20L2112%20A%20popular,performing%20ones%20early">[16]</a> <a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=Hyperband%20solves%20this%20problem%20by,where">[17]</a> <a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=An%20example%20Hyperband%20schedule%20is,hyperparameter%20configurations%3B%20note%20that%20each">[18]</a> <a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#:~:text=low,0">[47]</a> 5  Advanced Tuning Methods and Black Box Optimization – Applied Machine Learning Using mlr3 in R</p>
<p><a href="https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html">https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html</a></p>
<p><a href="https://arxiv.org/abs/1901.07329#:~:text=feature%20engineering%20and%20selection%20capabilities,meaningful%20features%20is%20selected%2C%20which">[26]</a> [1901.07329] The autofeat Python Library for Automated Feature Engineering and Selection</p>
<p><a href="https://arxiv.org/abs/1901.07329">https://arxiv.org/abs/1901.07329</a></p>
<p><a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf#:~:text=II,explain%20the%20motivation%20for%20Deep">[27]</a> <a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf#:~:text=generates%20features%20for%20relational%20datasets,abstractions%2C%20and%20present%20the%20algorithm">[28]</a> groups.csail.mit.edu</p>
<p><a href="https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf">https://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf</a></p>
<p><a href="https://cloud.google.com/blog/products/ai-machine-learning/new-automl-features-and-end-to-end-workflows-on-ai-platform-pipelines#:~:text=AutoML%20Tables%20%20lets%20you,46%2C%20and%20more">[29]</a> New AutoML features and end-to-end workflows on AI Platform Pipelines | Google Cloud Blog</p>
<p><a href="https://cloud.google.com/blog/products/ai-machine-learning/new-automl-features-and-end-to-end-workflows-on-ai-platform-pipelines">https://cloud.google.com/blog/products/ai-machine-learning/new-automl-features-and-end-to-end-workflows-on-ai-platform-pipelines</a></p>
<p><a href="https://medium.com/googledeveloperseurope/make-your-life-easier-with-automl-tables-on-google-cloud-8a745c4e7f67#:~:text=So%2C%20I%20suggested%20him%20to,results%20ready%20the%20next%20morning">[30]</a> Make your life easier with AutoML Tables on Google Cloud! | by Ilias Papachristos | Google for Developers EMEA | Medium</p>
<p><a href="https://medium.com/googledeveloperseurope/make-your-life-easier-with-automl-tables-on-google-cloud-8a745c4e7f67">https://medium.com/googledeveloperseurope/make-your-life-easier-with-automl-tables-on-google-cloud-8a745c4e7f67</a></p>
<p><a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Meta,the%20need%20for%20manual%20intervention">[31]</a> <a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Meta,the%20need%20for%20manual%20intervention">[32]</a> <a href="https://medium.com/@anixlynch/meta-learning-in-automl-more-accurate-than-traditional-ml-3be72215db0d#:~:text=Besides%20Auto,learning">[40]</a> Meta-Learning in AutoML: More Accurate Than Traditional ML? | by Anix Lynch, MBA, ex-VC | Medium</p>
<p><a href="&#109;&#x61;&#x69;&#108;&#116;&#x6f;&#58;&#x68;&#116;&#116;&#112;&#115;&#x3a;&#x2f;&#x2f;&#109;&#101;&#100;&#105;&#x75;&#109;&#46;&#x63;&#111;&#x6d;&#x2f;&#64;&#97;&#x6e;&#x69;&#x78;&#108;&#121;&#110;&#99;&#104;&#47;&#109;&#x65;&#116;&#97;&#45;&#108;&#101;&#97;&#114;&#x6e;&#x69;&#x6e;&#x67;&#x2d;&#x69;&#x6e;&#x2d;&#x61;&#117;&#116;&#x6f;&#109;&#x6c;&#45;&#x6d;&#111;&#114;&#101;&#45;&#x61;&#99;&#x63;&#x75;&#x72;&#97;&#116;&#x65;&#x2d;&#116;&#104;&#97;&#110;&#x2d;&#x74;&#x72;&#x61;&#100;&#x69;&#116;&#x69;&#x6f;&#110;&#97;&#x6c;&#x2d;&#109;&#108;&#45;&#51;&#x62;&#x65;&#x37;&#50;&#x32;&#49;&#x35;&#x64;&#98;&#48;&#100;">&#x68;&#116;&#116;&#112;&#115;&#x3a;&#x2f;&#x2f;&#109;&#101;&#100;&#105;&#x75;&#109;&#46;&#x63;&#111;&#x6d;&#x2f;&#64;&#97;&#x6e;&#x69;&#x78;&#108;&#121;&#110;&#99;&#104;&#47;&#109;&#x65;&#116;&#97;&#45;&#108;&#101;&#97;&#114;&#x6e;&#x69;&#x6e;&#x67;&#x2d;&#x69;&#x6e;&#x2d;&#x61;&#117;&#116;&#x6f;&#109;&#x6c;&#45;&#x6d;&#111;&#114;&#101;&#45;&#x61;&#99;&#x63;&#x75;&#x72;&#97;&#116;&#x65;&#x2d;&#116;&#104;&#97;&#110;&#x2d;&#x74;&#x72;&#x61;&#100;&#x69;&#116;&#x69;&#x6f;&#110;&#97;&#x6c;&#x2d;&#109;&#108;&#45;&#51;&#x62;&#x65;&#x37;&#50;&#x32;&#49;&#x35;&#x64;&#98;&#48;&#100;</a></p>
<p><a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Introduction%20to%20Auto">[33]</a> <a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=A%20second%20method%20used%20by,and%20to%20optimize%20calculation%20time">[34]</a> <a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Auto,is%20very%20expensive%20to%20calculate">[35]</a> <a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=TPOT%20%28Tree,the%20best%20individuals%20are%20retained">[36]</a> <a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=TPOT%20supports%20a%20wide%20variety,and%20train%20the%20ML%20model">[37]</a> <a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=Because%20of%20the%20use%20of,time%20the%20model%20is%20trained">[38]</a> <a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries#:~:text=As%20seen%20above%2C%20TPOT%20is,it%20doesn%27t%20require%20programming%20knowledge">[39]</a> TPOT vs Auto-sklearn: comparing two AutoML libraries | Aqsone</p>
<p><a href="https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries">https://www.aqsone.com/en/blog/tpot-vs-auto-sklearn-comparing-two-automl-libraries</a></p>
<p><a href="https://commons.wikimedia.org/wiki/File:AutoML_diagram.png#:~:text=English%3A%20%20This%20Figure%20illustrates,Model%20Generation%2C%20and%20Model%20Evaluation">[42]</a> File:AutoML diagram.png - Wikimedia Commons</p>
<p><a href="https://commons.wikimedia.org/wiki/File:AutoML_diagram.png">https://commons.wikimedia.org/wiki/File:AutoML_diagram.png</a></p>
<p><a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=%2A%20Reinforcement%20Learning,move%20forward%20in%20the%20search">[46]</a> <a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=This%20is%20where%20zero,architecture%20without%20fully%20training%20it">[48]</a> <a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Similarly%2C%20zero,skipping%20the%20costly%20training%20phase">[50]</a> <a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Define%20Zero">[51]</a> <a href="https://medium.com/@amit25173/zero-cost-proxies-for-neural-architecture-search-1c317d757629#:~:text=Yadav%20medium.com%20%20Zero,skipping%20the%20costly%20training%20phase">[52]</a> Zero-Cost Proxies for Neural Architecture Search | by Amit Yadav | Medium</p>
<p><a href="&#x6d;&#97;&#x69;&#x6c;&#116;&#111;&#58;&#104;&#116;&#116;&#x70;&#115;&#58;&#x2f;&#x2f;&#109;&#101;&#x64;&#x69;&#117;&#x6d;&#46;&#x63;&#x6f;&#x6d;&#47;&#64;&#x61;&#109;&#105;&#x74;&#x32;&#53;&#x31;&#x37;&#x33;&#x2f;&#122;&#101;&#x72;&#x6f;&#x2d;&#99;&#111;&#x73;&#116;&#x2d;&#x70;&#114;&#x6f;&#120;&#x69;&#101;&#x73;&#x2d;&#102;&#x6f;&#114;&#45;&#110;&#101;&#x75;&#x72;&#x61;&#x6c;&#45;&#x61;&#114;&#x63;&#x68;&#105;&#x74;&#x65;&#99;&#x74;&#117;&#114;&#x65;&#x2d;&#115;&#101;&#97;&#114;&#x63;&#104;&#x2d;&#x31;&#x63;&#51;&#x31;&#55;&#x64;&#55;&#53;&#x37;&#54;&#x32;&#x39;">&#104;&#116;&#116;&#x70;&#115;&#58;&#x2f;&#x2f;&#109;&#101;&#x64;&#x69;&#117;&#x6d;&#46;&#x63;&#x6f;&#x6d;&#47;&#64;&#x61;&#109;&#105;&#x74;&#x32;&#53;&#x31;&#x37;&#x33;&#x2f;&#122;&#101;&#x72;&#x6f;&#x2d;&#99;&#111;&#x73;&#116;&#x2d;&#x70;&#114;&#x6f;&#120;&#x69;&#101;&#x73;&#x2d;&#102;&#x6f;&#114;&#45;&#110;&#101;&#x75;&#x72;&#x61;&#x6c;&#45;&#x61;&#114;&#x63;&#x68;&#105;&#x74;&#x65;&#99;&#x74;&#117;&#114;&#x65;&#x2d;&#115;&#101;&#97;&#114;&#x63;&#104;&#x2d;&#x31;&#x63;&#51;&#x31;&#55;&#x64;&#55;&#53;&#x37;&#54;&#x32;&#x39;</a></p>
<p><a href="https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/#:~:text=Zero,The%20method">[49]</a> A Deeper Look at Zero-Cost Proxies for Lightweight NAS</p>
<p><a href="https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/">https://iclr-blog-track.github.io/2022/03/25/zero-cost-proxies/</a></p>
<p><a href="https://arxiv.org/html/2505.09344v1#:~:text=...%20arxiv.org%20%20Zero,recent%20proxies%20often%20lack">[53]</a> Ensembling Zero-Cost Proxies to Estimate Performance of Neural ...</p>
<p><a href="https://arxiv.org/html/2505.09344v1">https://arxiv.org/html/2505.09344v1</a></p>
<p><a href="https://medium.com/@bibhushabibhs/aws-automl-no-code-machine-learning-in-amazon-sagemaker-autopilot-f5d7e0be4e6a#:~:text=AWS%20AutoML%20%E2%80%94%20No%20Code,Hyper%20Parameter">[59]</a> AWS AutoML — No Code Machine Learning in Amazon Sagemaker ...</p>
<p><a href="&#109;&#x61;&#x69;&#108;&#x74;&#x6f;&#58;&#x68;&#116;&#116;&#112;&#x73;&#x3a;&#x2f;&#x2f;&#x6d;&#x65;&#100;&#105;&#x75;&#x6d;&#46;&#x63;&#111;&#x6d;&#x2f;&#64;&#x62;&#x69;&#x62;&#x68;&#117;&#x73;&#x68;&#97;&#98;&#x69;&#98;&#104;&#x73;&#x2f;&#97;&#x77;&#115;&#x2d;&#x61;&#117;&#x74;&#x6f;&#109;&#108;&#45;&#110;&#111;&#45;&#99;&#111;&#x64;&#101;&#x2d;&#109;&#x61;&#x63;&#104;&#105;&#x6e;&#x65;&#x2d;&#x6c;&#101;&#x61;&#x72;&#110;&#x69;&#x6e;&#x67;&#45;&#x69;&#x6e;&#45;&#x61;&#109;&#x61;&#122;&#111;&#110;&#x2d;&#115;&#x61;&#103;&#x65;&#109;&#x61;&#x6b;&#101;&#x72;&#x2d;&#x61;&#117;&#116;&#111;&#x70;&#x69;&#x6c;&#111;&#x74;&#x2d;&#x66;&#x35;&#100;&#55;&#101;&#48;&#x62;&#101;&#x34;&#101;&#x36;&#97;">&#x68;&#116;&#116;&#112;&#x73;&#x3a;&#x2f;&#x2f;&#x6d;&#x65;&#100;&#105;&#x75;&#x6d;&#46;&#x63;&#111;&#x6d;&#x2f;&#64;&#x62;&#x69;&#x62;&#x68;&#117;&#x73;&#x68;&#97;&#98;&#x69;&#98;&#104;&#x73;&#x2f;&#97;&#x77;&#115;&#x2d;&#x61;&#117;&#x74;&#x6f;&#109;&#108;&#45;&#110;&#111;&#45;&#99;&#111;&#x64;&#101;&#x2d;&#109;&#x61;&#x63;&#104;&#105;&#x6e;&#x65;&#x2d;&#x6c;&#101;&#x61;&#x72;&#110;&#x69;&#x6e;&#x67;&#45;&#x69;&#x6e;&#45;&#x61;&#109;&#x61;&#122;&#111;&#110;&#x2d;&#115;&#x61;&#103;&#x65;&#109;&#x61;&#x6b;&#101;&#x72;&#x2d;&#x61;&#117;&#116;&#111;&#x70;&#x69;&#x6c;&#111;&#x74;&#x2d;&#x66;&#x35;&#100;&#55;&#101;&#48;&#x62;&#101;&#x34;&#101;&#x36;&#97;</a></p>
<p><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html#:~:text=After%20the%20experiment%20runs%2C%20you,or%20the%20candidate%20model%20definitions">[60]</a> <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html#:~:text=">[61]</a> Create Regression or Classification Jobs for Tabular Data Using the AutoML API - Amazon SageMaker AI</p>
<p><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html">https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html</a></p>
