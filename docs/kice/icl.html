<h1 id="in-context-learning-">In-Context Learning: 개념, 특징, 한계와 미래 방향</h1>
<h2 id="1-in-context-learning-">1. 개념적 배경: In-Context Learning이란 무엇인가?</h2>
<p><strong>In-Context Learning(ICL)</strong>은 대규모 언어 모델이 별도의 파라미터 업데이트 없이 <strong>주어진 문맥(context)</strong>을 통해 새로운 작업을 학습하는 능력을 뜻합니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=In,and%20keeps%20their%20parameters%20unchanged">[1]</a>. 예를 들어 GPT-3 같은 대규모 언어 모델에 몇 개의 입력-출력 <strong>예시</strong>를 프롬프트로 제공하면, 모델이 그 <strong>패턴을 이해</strong>하여 새로운 입력에 대한 출력도 추론해내는 것입니다<a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=But%20that%E2%80%99s%20not%20all%20these,can%20give%20the%20correct%20sentiment">[2]</a>. 이는 모델이 <strong>훈련되지 않은 작업도</strong> 몇 가지 예시만 보고 수행할 수 있는 놀라운 현상으로, 사람으로 치면 시험 전에 기출문제 몇 개 풀어보고 유추해서 푸는 셈입니다.</p>
<p>이러한 접근은 <strong>전통적인 파인튜닝(fine-tuning)</strong> 방식과 크게 대비됩니다. 일반적인 머신러닝에서는 새로운 과제를 풀 때 <strong>추가 데이터로 모델을 재훈련</strong>하며, 이 과정에서 <strong>경사하강법(gradient descent)</strong>으로 모델 파라미터를 업데이트하게 됩니다<a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=Typically%2C%20a%20machine,so%20it%20seems%20like%20the">[3]</a>. 반면 <strong>In-Context Learning</strong>에서는 <strong>모델 파라미터를 전혀 변경하지 않고</strong>, 프롬프트에 포함된 예시와 지시만으로 <strong>즉석에서</strong> 모델의 출력을 조정합니다<a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/#:~:text=Unlike%20fine,model%20on%20a%20specific%20dataset">[4]</a>. 요컨대 파인튜닝은 모델의 <strong>가중치를 바꾸어</strong> 장기적인 지식을 주입하는 반면, ICL은 <strong>프롬프트 설계만으로</strong> 모델의 <strong>단기 행동</strong>을 유도하는 것입니다<a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/#:~:text=Here%20are%20five%20key%20differences,to%20make%20this%20more%20clear">[5]</a>. 이 덕분에 ICL은 새로운 데이터셋으로 재학습할 필요 없이 <strong>바로바로 적용 가능한 유연성</strong>을 보여주지만, 한편으로 모델 파라미터에 영구적인 변화가 없기 때문에 맥락이 바뀌면 학습 내용도 사라진다는 특성이 있습니다.</p>
<h2 id="2-gpt-3-in-context-learning-">2. 주요 연구 동향: GPT-3 이후의 In-Context Learning 발전</h2>
<p>ICL 개념은 2020년 OpenAI의 <strong>GPT-3 모델</strong>을 통해 대중적으로 주목받았습니다. GPT-3 논문 제목이 <em>“Language Models are Few-Shot Learners”</em>일 정도로, GPT-3는 방대한 매개변수를 통해 <strong>추가 학습 없이도</strong> 다양한 NLP 작업을 몇 가지 예시만으로 수행해냈습니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=research%20paper%20%E2%80%9CLanguage%20Models%20are,and%20keeps%20their%20parameters%20unchanged">[6]</a>. 이로써 대규모 언어 모델에서 <strong>Few-Shot 학습</strong>(적은 예시로 학습)이 새로운 패러다임으로 떠오르게 되었습니다. 이후 연구자들은 왜 큰 모델들이 이런 능력을 보이는지 분석하고, 더 작은 모델이나 더 어려운 작업에서도 ICL 성능을 높이기 위한 시도를 이어갔습니다.</p>
<p>특히 GPT-3 이후에는 <strong>메타러닝(meta-learning)</strong> 기법을 접목한 ICL 향상 연구가 활발했습니다. 예를 들어 2022년 발표된 <strong>MetaICL</strong>은 사전에 다양한 작업들에 대해 <strong>메타-트레이닝</strong>을 함으로써, <strong>Few-Shot 프롬프트 학습 능력</strong>을 개선한 프레임워크입니다<a href="https://arxiv.org/abs/2110.15943#:~:text=%3E%20Abstract%3AWe%20introduce%20MetaICL%20%28Meta,MetaICL%20outperforms%20a%20range%20of">[7]</a>. 간단히 말해, <strong>여러 NLP 과제들</strong>을 모델에게 프롬프트로 푸는 연습을 시켜둠으로써 새로운 과제를 몇 가지 예시만으로도 더 잘 풀도록 만든 것입니다. MetaICL은 <strong>별도의 파인튜닝 없이</strong> 순수 ICL로 여러 벤치마크에서 향상된 성능을 보였고, 때로는 <strong>완전히 미세조정한 모델</strong>에 맞먹는 정확도를 달성하기도 했습니다<a href="https://arxiv.org/abs/2110.15943#:~:text=of%20tasks%20consisting%20of%20142,target%20task%2C%20and%20outperforms%20much">[8]</a>. 또한 매개변수가 8배나 큰 거대 모델보다도 높은 성능을 내는 등, <strong>메타학습을 통해 ICL 능력을 향상</strong>시킬 수 있다는 것을 보여주었습니다<a href="https://arxiv.org/abs/2110.15943#:~:text=seven%20different%20meta,we%20show%20that%20MetaICL%20is">[9]</a>.</p>
<p>ICL 능력을 향상시키는 또 다른 흐름은 <strong>프롬프트 기법 연구</strong>입니다. 2022년에는 <strong>Chain-of-Thought (연쇄 사고) 프롬프팅</strong>이 제안되어 복잡한 추론 문제가 개선되었습니다. 이는 프롬프트 예시에 <strong>중간 추론 단계를 자세히 기술</strong>함으로써, 모델이 답을 도출하기 전에 단계별로 생각을 전개하도록 유도하는 기법입니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=%2A%20Few,are%20provided">[10]</a>. 예를 들어 산수 문제를 풀 때 <strong>“생각을 차근차근 해보자”</strong> 같은 문장을 넣거나, 몇 가지 풀이 과정을 보여주면 모델이 <strong>추론 능력</strong>을 발휘해 더 정확한 답을 내놓는 식입니다. 이 기법은 큰 모델일수록 효과적이며, Google의 거대 모델 <strong>PaLM</strong>에서는 특정 크기 이상에서 이러한 <strong>연쇄적 추론 능력이 갑자기 향상되는</strong> 현상이 보고되기도 했습니다 (일종의 <strong>Emergent Ability</strong>, 돌연 능력의 발현). 이처럼 <strong>프롬프트 설계</strong>를 통해 ICL 성능을 높이는 연구가 GPT-3 이후 다각도로 진행되었습니다.</p>
<p>더 나아가, Stanford 등 연구팀은 ICL과 <strong>추론 알고리즘</strong>의 접목을 시도했습니다. 2023년 소개된 <strong>TART</strong>라는 접근은, 모델에게 특정 작업 지식이 아니라 <strong>일반적인 추론 능력</strong>을 가르쳐 ICL의 한계를 보완하려 한 것입니다. 예컨대 <strong>확률적 논리 추론</strong> 같은 <strong>과제-독립적인 훈련</strong>을 추가로 시켜주었더니, 모델이 프롬프트 예시를 가지고 <strong>보다 논리적인 추론</strong>을 하게 되어 ICL과 기존 파인튜닝 간의 성능 차이가 크게 줄었습니다<a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=Roughly%2C%20fine,the%20source%20of%20the%20gap">[11]</a><a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=problem%20,This%20suggested%20to%20us%20that">[12]</a>. 이러한 연구는 <strong>대형 언어모델 내부에 작은 모델(예: 선형 모델)을 잠재적으로 학습시킬 수 있다</strong>는 이론적 분석<a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=Scientists%20from%20MIT%2C%20Google%20Research%2C,can%20learn%20without%20updating%20parameters">[13]</a>에 기반을 둔 것으로, 결과적으로 ICL의 성능 격차를 메꾸고 <strong>추론 안정성</strong>을 높이는 새로운 방향으로 주목받고 있습니다.</p>
<h2 id="3-in-context-learning-">3. In-Context Learning의 주요 특징</h2>
<p>ICL의 두드러진 특징으로는 <strong>학습 방식의 유연성</strong>과 <strong>범용성</strong>을 들 수 있습니다. 아래에 ICL의 대표적 특징들을 정리합니다.</p>
<ul>
<li><strong>Zero-shot/One-shot/Few-shot 학습</strong>: ICL은 프롬프트에 몇 개의 <strong>데모 예시(demonstration)</strong>를 제공하는지만으로 학습 양을 조절합니다. <strong>Zero-shot</strong> 학습은 <strong>예시를 전혀 주지 않고</strong> 문제 설명만으로 답하도록 하는 방식이고, <strong>One-shot</strong>은 <strong>딱 하나의 예시</strong>를 제공하는 경우, <strong>Few-shot</strong>은 <strong>여러 개의 예시</strong>(보통 3~5개 등)를 포함하는 경우를 말합니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=%2A%20Zero,explained%20without%20providing%20any%20examples">[14]</a>. 예를 들어 <strong>Zero-shot</strong>으로 <em>“이 문장의 감정을 분석하라”</em>라고 지시하거나, <strong>One-shot</strong>으로 <em>“영화 좋았어 → 긍정”</em> 한 가지 예를 준 뒤 새로운 문장을 묻거나, <strong>Few-shot</strong>으로 긍정/부정 예시를 여러 개 나열한 뒤 분류를 요구하는 식입니다. 예시의 수가 늘어나면 <strong>프롬프트 길이</strong>는 길어지지만 모델이 참고할 힌트가 많아져 대체로 성능이 개선됩니다 (물론 모델 크기와 과제 난이도에 따라 편차는 있습니다).</li>
<li><strong>프롬프트 설계와</strong> Task Generalization<strong><em>*: ICL에서는</em> *프롬프트 엔지니어링(prompt engineering)</strong>이 성능의 핵심 요소입니다. 모델이 <strong>맥락에서 학습</strong>하기 때문에, <strong>프롬프트의 표현 방식, 형식, 예시 배치 순서</strong> 등이 출력 품질에 큰 영향을 줍니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=chosen%20to%20match%20what%20the,smaller%20models%20or%20edge%20cases">[15]</a>. 잘 설계된 프롬프트는 모델이 무엇을 해야 하는지 명확히 인지하도록 도와주며, 결과적으로 <strong>훈련 때 보지 못한 작업</strong>도 일반화해내는 능력을 발휘합니다. 실제로 대형 언어모델은 인터넷 코퍼스에서 이미 방대한 유형의 텍스트 패턴을 학습했기 때문에, 프롬프트가 <strong>훈련 분포와 유사한 형식</strong>으로 주어지면 모델은 그동안 쌓은 지식을 동원해 새로운 작업도 해결하려 합니다<a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=For%20instance%2C%20GPT,its%20training%20dataset%20included%20text">[16]</a>. 이러한 <strong>작업 범용성</strong> 덕분에 한 번 훈련된 LLM이 <strong>질문 answering, 번역, 요약, 코딩</strong> 등 다방면에 바로 투입될 수 있게 되었습니다.</li>
<li><strong>Prompting 기법의 다양성</strong>: 앞서 언급한 <strong>Chain-of-Thought</strong> 프롬프팅처럼, ICL 맥락에서 여러 <strong>기법적 변주</strong>가 시도되고 있습니다. 프롬프트에 <strong>단계별 풀이과정</strong>을 넣어 <strong>추론 작업</strong>을 개선하는 <strong>연쇄 사고(prompt)</strong> 기법<a href="https://www.lakera.ai/blog/what-is-in-context-learning#:~:text=Chain,prompting%20for%20complex%20reasoning%20tasks">[17]</a>, 모델 스스로 프롬프트를 <strong>반성 및 개선</strong>하게 하는 <strong>RePrompt</strong> 기법, 사용자 지시를 잘 따르도록 별도 문장을 삽입하는 <strong>Instruction 프롬프팅</strong> 등이 있습니다. 이처럼 프롬프트를 어떤 방식으로 구성하느냐에 따라 <strong>ICL의 효과가 크게 달라지며</strong>, 다양한 아이디어가 등장해 <strong>Prompt 디자인</strong> 자체가 하나의 중요한 연구 분야로 자리 잡았습니다.</li>
<li><strong>학습의 일회성(온더플라이 학습)</strong>: ICL에서 모델은 프롬프트로 주어진 정보만을 참고하여 <strong>일시적으로</strong> 작업을 해결합니다. 즉 <strong>매 요청(Inference)</strong> 시마다 새로 학습을 하는 것과 비슷한 형태인데, 이는 마치 모델 내부에 <strong>내장된 문제 해결 엔진</strong>이 있어서, 주어진 예시를 토대로 그 자리에서 규칙을 만들어내는 것과 유사합니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=The%20AI%20model%20uses%20the,it%20highly%20flexible%20and%20efficient">[18]</a>. 이 특징 때문에 ICL은 <strong>메모리 기반 추론</strong>이라고도 볼 수 있는데, 모델의 <strong>컨텍스트 윈도우</strong>(맥락 창)에 담긴 정보만 활용하여 결과를 산출하기 때문입니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=At%20its%20core%2C%20in,model%20that%20processes%20sequential%20input">[19]</a>. 다만 이렇게 일회성으로 학습한 내용은 <strong>모델 파라미터에 축적되지 않고</strong>, 새로운 질의가 들어오면 다시 초기 상태에서 출발한다는 점에서 인간의 <strong>단기기억</strong>에 비유되곤 합니다.</li>
</ul>
<h2 id="4-">4. 남은 과제 및 한계점</h2>
<p>In-Context Learning은 흥미로운 가능성을 보여주지만, 동시에 여러 <strong>한계와 도전 과제</strong>를 안고 있습니다. 대표적인 이슈들은 다음과 같습니다:</p>
<ul>
<li><strong>성능 편차와 신뢰성 이슈</strong>: ICL의 성능은 아직 <strong>전통적 파인튜닝보다 들쑥날쑥한 경향</strong>이 있습니다. 여러 연구에서 <strong>같은 몇 샷 예시</strong>를 주더라도 출력 품질이 불안정하거나, <strong>Fine-tuned 모델보다 정확도가 떨어지는</strong> <strong>일관성 갭</strong>이 지적되었습니다<a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=AI,tuning.%20We%20wondered%3A%20why">[20]</a>. 예컨대 몇십 개의 예시를 프롬프트로 줘도, 차라리 그 데이터를 활용해 작은 분류기를 훈련한 경우보다 성능이 낮게 나오는 경우가 있습니다<a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=Roughly%2C%20fine,the%20source%20of%20the%20gap">[11]</a>. 이러한 <strong>성능 편차</strong>는 모델이 프롬프트 내 <strong>패턴 추론</strong>을 완벽히 해내지 못하거나, 내재된 <strong>추론 알고리즘의 한계</strong> 때문으로 여겨집니다. 결국 ICL을 실전에 활용하려면 <strong>출력의 신뢰성</strong>을 높이고, worst-case 시나리오에서도 안정적인 성능을 보장하는 추가 연구가 필요합니다.</li>
<li><strong>프롬프트 형식 민감성</strong>: ICL 모델들은 <strong>프롬프트의 표현</strong>에 매우 민감하여, <strong>미세한 차이</strong>에도 답이 달라질 수 있습니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=chosen%20to%20match%20what%20the,smaller%20models%20or%20edge%20cases">[15]</a>. 예를 들어 레이블을 긍정/부정 대신 positive/negative로 쓰거나, 예시의 순서를 바꾸거나, 문장 부호나 공백 처리만 달라져도 출력이 바뀌는 현상이 보고됩니다. 이러한 형식 민감성은 특히 작은 언어모델에서 두드러지지만 대형 모델에도 존재하며, <strong>프롬프트 최적화</strong>를 어렵게 만드는 요인입니다. 사용자는 종종 <strong>프롬프트 엔지니어링</strong>을 통해 여러 표현을 시험해보며 모델이 가장 안정적으로 응답하는 방식을 찾아야 합니다. 이 문제를 완화하기 위해 최근에는 <strong>프롬프트 자동 최적화</strong> 도구나, <strong>복수의 프롬프트 결과를 투표(ensemble)</strong>하여 안정적인 답을 취하는 기법 등이 연구되고 있습니다.</li>
<li><strong>데이터 분포 의존성과 편향</strong>: ICL의 효과는 <strong>사전훈련 데이터</strong>의 분포와 밀접한 연관이 있습니다. 모델이 훈련 중 접해보지 못한 형식의 질문이나, 매우 특이한 도메인의 작업에 대해서는 ICL이 제대로 작동하지 않을 수 있습니다. 이는 모델이 <strong>훈련 분포에서 학습한 패턴</strong>에 크게 의존하기 때문입니다<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=high,smaller%20models%20or%20edge%20cases">[21]</a>. 예를 들어 영어로 학습된 모델에 갑자기 생소한 형식의 형용사 평어를 섞은 입력을 주면 혼란스러워할 수 있습니다. 또한 훈련 데이터에 존재하던 <strong>편향(bias)</strong>이 ICL 시에도 고스란히 드러날 수 있다는 점도 한계입니다. 예시 몇 개로 편향을 바로잡기는 어렵기 때문에, 모델이 기존에 지닌 <strong>언어적 편향, 상식의 한계</strong> 등이 ICL 응답에 영향을 주어 <strong>공정성</strong> 이슈를 야기할 수 있습니다. 따라서 ICL을 신뢰성 있게 활용하려면, <strong>다양한 분포의 데이터</strong>로 사전학습을 하거나, 필요한 경우 <strong>명시적 지침</strong>을 주어 편향된 출력을 억제하는 등 보완책이 요구됩니다.</li>
<li><strong>메타러닝과의 관계</strong>: ICL 현상은 본질적으로 모델이 <strong>“학습하는 법을 학습”</strong>했다고 볼 수 있어 메타러닝과 밀접한 관련이 있습니다. GPT-3의 등장은 거대한 언어모델이 <strong>내재적으로 메타학습 능력</strong>을 획득한 예로 해석되었는데, 이는 모델이 훈련 중 다양한 작업을 접하며 <strong>맷집 있게 일반 학습 규칙</strong>을 체득했기 때문이라는 가설이 있습니다. 실제로 연구자들은 GPT-3가 <strong>내부적으로 작은 선형 모델을 은닉층에 훈련시키는 방식</strong>으로 ICL을 구현하고 있다는 이론적 근거를 제시하기도 했습니다<a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=Scientists%20from%20MIT%2C%20Google%20Research%2C,can%20learn%20without%20updating%20parameters">[13]</a>. 한편으로, <strong>명시적인 메타러닝 기법</strong>(예: MAML 등)을 적용하면 ICL 성능이 더 좋아질 수 있다는 실험도 나오고 있습니다<a href="https://arxiv.org/abs/2110.15943#:~:text=%3E%20Abstract%3AWe%20introduce%20MetaICL%20%28Meta,MetaICL%20outperforms%20a%20range%20of">[7]</a>. 결국 ICL은 대형 언어모델의 <strong>메타러닝적 특성</strong>이 발현된 것이라 볼 수 있으며, 이를 더 잘 이해하고 설계에 활용하는 것이 남은 과제입니다.</li>
</ul>
<h2 id="5-">5. 향후 과제 및 연구 방향</h2>
<p>In-Context Learning의 잠재력을 극대화하기 위해, 앞으로 여러 보완 기법과 새로운 방향이 모색되고 있습니다. <strong>AI 경력자</strong> 관점에서 주목할 만한 향후 연구 방향을 정리하면 다음과 같습니다:</p>
<ul>
<li><strong>Retrieval 기반 In-Context Learning</strong>: <strong>외부 지식 베이스</strong>나 <strong>예시 데이터베이스</strong>를 활용하여, 모델에 가장 적절한 문맥을 <strong>자동으로 삽입</strong>해주는 접근입니다. 일종의 <strong>RAG(Retrieval-Augmented Generation)</strong> 개념을 ICL에 접목한 것으로 볼 수 있습니다. 예를 들어 질문이 들어오면 관련 배경지식이나 유사한 Q&amp;A 예시를 <strong>검색(리트리벌)</strong>하여, 이를 프롬프트에 추가함으로써 모델이 더 풍부한 정보 속에서 작업을 수행하도록 하는 것입니다<a href="https://medium.com/@IParra/how-to-supercharge-a-llm-retrieval-augmented-in-context-learning-ra-icl-629c269235c7#:~:text=Retrieval,learning%20differs%20by%20its%20fluidity">[22]</a><a href="https://medium.com/@IParra/how-to-supercharge-a-llm-retrieval-augmented-in-context-learning-ra-icl-629c269235c7#:~:text=%3E%20Retrieval,with%20additional%20%E2%80%93and%20relevant%E2%80%93%20context">[23]</a>. 이렇게 하면 <strong>고정된 예시 세트</strong>에 의존하지 않고 <strong>상황에 맞는 예시</strong>를 실시간으로 제공할 수 있어 성능 향상에 도움이 됩니다. 실제 사례로, 대규모 법률 문서를 요약하는 작업에서 먼저 관련 조항을 검색해 프롬프트에 넣거나, 번역 시 유사 문장쌍을 데이터베이스에서 찾아 제공하는 식의 연구가 진행되고 있습니다. 다만 이 방식은 <strong>추가적인 검색 인프라</strong>와 <strong>임베딩 모델</strong>이 필요하고, 실시간 검색으로 인한 <strong>지연</strong>이 생길 수 있어 효율성 측면의 최적화가 과제로 남습니다.</li>
<li><strong>동적 프롬프트 최적화</strong>: 정적인 프롬프트 대신 <strong>입력에 맞춰 예시를 유동적으로 선택하거나 편집</strong>하는 기법입니다. 이는 위의 리트리버와도 연관되지만, 더 일반적으로는 <strong>주어진 문제에 가장 효과적인 프롬프트를 자동으로 구성</strong>하려는 노력입니다. 예를 들어 <strong>Dynamic Few-Shot Prompting</strong>은 미리 많은 예시를 준비해두고, 실제 질문과 가장 유사하면서 도움될 만한 <strong>상위 k개의 예시</strong>만 골라 프롬프트를 구성하는 방법입니다<a href="https://medium.com/@stefansipinkoski/optimizing-ai-agents-with-dynamic-few-shot-prompting-585919f694cc#:~:text=Dynamic%20few,hand">[24]</a><a href="https://medium.com/@stefansipinkoski/optimizing-ai-agents-with-dynamic-few-shot-prompting-585919f694cc#:~:text=relevant%2C%20thereby%20improving%20the%20model%E2%80%99s,shot%20prompting%20aims%20to%20achieve">[25]</a>. 이렇게 하면 불필요하게 긴 예시나 무관한 예시로 인한 <strong>혼선</strong>을 줄이고, <strong>적은 토큰</strong>으로도 <strong>효율적인 학습 힌트</strong>를 제공할 수 있습니다. 또한 최근엔 <strong>Prompt Tuning</strong>이라 하여, 아예 프롬프트 자체를 모델이 학습하도록 (예: 몇 개의 가상 토큰을 최적화하여) 만드는 방법도 제안되었습니다. 이는 ICL과 파인튜닝의 중간쯤 되는 접근으로, 모델 파라미터는 고정한 채 <strong>프롬프트 벡터</strong>만 훈련시키는 것입니다. 향후에는 사용자 피드백을 반영해 프롬프트를 자동으로 개선하는 <strong>RLHF 기반 프롬프트 최적화</strong>나, 여러 번의 대화 맥락을 거치며 프롬프트를 점진적으로 다듬는 <strong>대화형 프롬프트 최적화</strong> 등도 기대해볼 수 있습니다.</li>
<li><strong>Instruction Tuning과의 융합</strong>: Instruction Tuning은 모델을 <strong>사용자 지시어(Instruction)</strong>에 잘 따르도록 별도로 미세조정하는 기법으로, GPT-3 이후 <strong>InstructGPT</strong>, Google <strong>FLAN</strong> 등에서 널리 활용되었습니다. 이러한 Instruction 튜닝이 잘 된 모델은 <strong>Zero-shot 성능</strong>이 크게 향상되고, 사용자 질문만으로도 상당히 유용한 답변을 생산해냅니다. 앞으로의 연구에서는 <strong>ICL의 few-shot 능력</strong>과 <strong>Instruction following 능력</strong>을 어떻게 조화롭게 결합할지가 중요한 주제가 될 것입니다. 한 연구에서는 Instruction 튜닝이 모델의 입력-출력 매핑 학습 능력을 향상시키지만 동시에 <strong>모델이 가지고 있는 선험적 지식(semantic priors)에 더 의존</strong>하게 만든다고 지적하며, <strong>적절한 균형</strong>이 필요하다고 합니다<a href="https://www.lakera.ai/blog/what-is-in-context-learning#:~:text=While%20instruction%20tuning%20enhances%20the,tool%20for%20optimizing%20ICL%20performance">[26]</a>. 향후에는 한 모델이 <strong>지시 기반 학습</strong>과 <strong>맥락 예시 기반 학습</strong>을 모두 잘 해내도록, 두 방식의 훈련을 통합하거나 보완적으로 적용하는 기법들이 나올 수 있습니다. 예를 들어 <strong>Instruction 튜닝된 모델</strong>에 추가로 few-shot 예시를 주면 성능이 더 향상되는지, 혹은 반대로 몇-shot 예시로 학습한 뒤 간단한 지시어로 마무리하는 조합 등이 검토될 수 있습니다. <strong>ChatGPT</strong>와 같은 최신 모델들은 이미 방대한 지시문 데이터로 튜닝되어 나오지만, 동시에 예시 기반의 유연한 적응력도 갖추고 있어 이러한 <strong>융합 접근의 가능성</strong>을 보여주고 있습니다.</li>
</ul>
<p>그 밖에도 <strong>맥락 창 크기의 확대</strong>(long context 지원), <strong>모달리티 확장</strong>(텍스트 외에 이미지나 음성에 대해서도 ICL 적용), <strong>추론 과정의 투명성 확보</strong>(왜 그런 답을 냈는지 설명 가능하게) 등 다양한 연구 과제가 남아 있습니다. In-Context Learning은 등장한 지 몇 년 되지 않았지만 급속히 발전하고 있으며, <strong>대형 언어 모델 시대의 핵심 기술</strong>로 자리매김하고 있습니다. 앞으로 ICL의 한계들을 보완하고 다른 기법들과 융합함으로써, 인간처럼 <strong>주어진 상황에 맞게 즉석에서 배워가는 AI</strong>에 한 걸음 더 다가갈 것으로 기대됩니다.</p>
<p><strong>참고문헌:</strong> GPT-3 논문<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=research%20paper%20%E2%80%9CLanguage%20Models%20are,and%20keeps%20their%20parameters%20unchanged">[6]</a>, EntryPoint AI 블로그<a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/#:~:text=Unlike%20fine,model%20on%20a%20specific%20dataset">[4]</a><a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/#:~:text=Here%20are%20five%20key%20differences,to%20make%20this%20more%20clear">[5]</a>, Stanford Hazy Research 블로그<a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=AI,tuning.%20We%20wondered%3A%20why">[20]</a><a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=problem%20,This%20suggested%20to%20us%20that">[12]</a>, IBM AI 전략 보고서<a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=chosen%20to%20match%20what%20the,smaller%20models%20or%20edge%20cases">[15]</a><a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=%2A%20Zero,explained%20without%20providing%20any%20examples">[14]</a>, MIT 뉴스 기사<a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=But%20that%E2%80%99s%20not%20all%20these,can%20give%20the%20correct%20sentiment">[2]</a><a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=Scientists%20from%20MIT%2C%20Google%20Research%2C,can%20learn%20without%20updating%20parameters">[13]</a> 등.</p>
<p><a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=In,and%20keeps%20their%20parameters%20unchanged">[1]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=research%20paper%20%E2%80%9CLanguage%20Models%20are,and%20keeps%20their%20parameters%20unchanged">[6]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=%2A%20Few,are%20provided">[10]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=%2A%20Zero,explained%20without%20providing%20any%20examples">[14]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=chosen%20to%20match%20what%20the,smaller%20models%20or%20edge%20cases">[15]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=The%20AI%20model%20uses%20the,it%20highly%20flexible%20and%20efficient">[18]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=At%20its%20core%2C%20in,model%20that%20processes%20sequential%20input">[19]</a> <a href="https://www.ibm.com/think/topics/in-context-learning#:~:text=high,smaller%20models%20or%20edge%20cases">[21]</a> What is In-Context Learning (ICL)? | IBM</p>
<p><a href="https://www.ibm.com/think/topics/in-context-learning">https://www.ibm.com/think/topics/in-context-learning</a></p>
<p><a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=But%20that%E2%80%99s%20not%20all%20these,can%20give%20the%20correct%20sentiment">[2]</a> <a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=Typically%2C%20a%20machine,so%20it%20seems%20like%20the">[3]</a> <a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=Scientists%20from%20MIT%2C%20Google%20Research%2C,can%20learn%20without%20updating%20parameters">[13]</a> <a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207#:~:text=For%20instance%2C%20GPT,its%20training%20dataset%20included%20text">[16]</a> Solving a machine-learning mystery | MIT News | Massachusetts Institute of Technology</p>
<p><a href="https://news.mit.edu/2023/large-language-models-in-context-learning-0207">https://news.mit.edu/2023/large-language-models-in-context-learning-0207</a></p>
<p><a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/#:~:text=Unlike%20fine,model%20on%20a%20specific%20dataset">[4]</a> <a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/#:~:text=Here%20are%20five%20key%20differences,to%20make%20this%20more%20clear">[5]</a> Pre-training vs Fine-Tuning vs In-Context Learning of Large Language Models | Entry Point AI</p>
<p><a href="https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/">https://www.entrypointai.com/blog/pre-training-vs-fine-tuning-vs-in-context-learning-of-large-language-models/</a></p>
<p><a href="https://arxiv.org/abs/2110.15943#:~:text=%3E%20Abstract%3AWe%20introduce%20MetaICL%20%28Meta,MetaICL%20outperforms%20a%20range%20of">[7]</a> <a href="https://arxiv.org/abs/2110.15943#:~:text=of%20tasks%20consisting%20of%20142,target%20task%2C%20and%20outperforms%20much">[8]</a> <a href="https://arxiv.org/abs/2110.15943#:~:text=seven%20different%20meta,we%20show%20that%20MetaICL%20is">[9]</a> [2110.15943] MetaICL: Learning to Learn In Context</p>
<p><a href="https://arxiv.org/abs/2110.15943">https://arxiv.org/abs/2110.15943</a></p>
<p><a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=Roughly%2C%20fine,the%20source%20of%20the%20gap">[11]</a> <a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=problem%20,This%20suggested%20to%20us%20that">[12]</a> <a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning#:~:text=AI,tuning.%20We%20wondered%3A%20why">[20]</a> Why is in-context learning lower quality than fine-tuning? And…what if it wasn&#39;t? · Hazy Research</p>
<p><a href="https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning">https://hazyresearch.stanford.edu/blog/2023-06-12-icl-vs-finetuning</a></p>
<p><a href="https://www.lakera.ai/blog/what-is-in-context-learning#:~:text=Chain,prompting%20for%20complex%20reasoning%20tasks">[17]</a> <a href="https://www.lakera.ai/blog/what-is-in-context-learning#:~:text=While%20instruction%20tuning%20enhances%20the,tool%20for%20optimizing%20ICL%20performance">[26]</a> What is In-context Learning, and how does it work: The Beginner’s Guide | Lakera – Protecting AI teams that disrupt the world.</p>
<p><a href="https://www.lakera.ai/blog/what-is-in-context-learning">https://www.lakera.ai/blog/what-is-in-context-learning</a></p>
<p><a href="https://medium.com/@IParra/how-to-supercharge-a-llm-retrieval-augmented-in-context-learning-ra-icl-629c269235c7#:~:text=Retrieval,learning%20differs%20by%20its%20fluidity">[22]</a> <a href="https://medium.com/@IParra/how-to-supercharge-a-llm-retrieval-augmented-in-context-learning-ra-icl-629c269235c7#:~:text=%3E%20Retrieval,with%20additional%20%E2%80%93and%20relevant%E2%80%93%20context">[23]</a> How To Supercharge an LLM: Retrieval-Augmented In-Context Learning (RA-ICL) | by Iñigo Parra | Medium</p>
<p><a href="&#x6d;&#x61;&#105;&#x6c;&#116;&#111;&#x3a;&#x68;&#x74;&#116;&#112;&#x73;&#x3a;&#47;&#x2f;&#109;&#x65;&#100;&#105;&#x75;&#109;&#x2e;&#99;&#x6f;&#109;&#47;&#64;&#73;&#x50;&#x61;&#114;&#114;&#x61;&#x2f;&#104;&#111;&#x77;&#x2d;&#116;&#x6f;&#x2d;&#115;&#117;&#112;&#x65;&#x72;&#x63;&#104;&#97;&#114;&#x67;&#x65;&#x2d;&#97;&#x2d;&#108;&#108;&#109;&#x2d;&#x72;&#x65;&#x74;&#114;&#105;&#101;&#118;&#97;&#x6c;&#45;&#97;&#117;&#x67;&#x6d;&#x65;&#110;&#x74;&#x65;&#x64;&#x2d;&#105;&#x6e;&#x2d;&#99;&#111;&#x6e;&#x74;&#101;&#120;&#116;&#45;&#108;&#x65;&#x61;&#x72;&#110;&#105;&#110;&#x67;&#x2d;&#114;&#x61;&#45;&#x69;&#x63;&#108;&#45;&#x36;&#50;&#x39;&#x63;&#x32;&#54;&#x39;&#50;&#51;&#x35;&#99;&#x37;">&#x68;&#x74;&#116;&#112;&#x73;&#x3a;&#47;&#x2f;&#109;&#x65;&#100;&#105;&#x75;&#109;&#x2e;&#99;&#x6f;&#109;&#47;&#64;&#73;&#x50;&#x61;&#114;&#114;&#x61;&#x2f;&#104;&#111;&#x77;&#x2d;&#116;&#x6f;&#x2d;&#115;&#117;&#112;&#x65;&#x72;&#x63;&#104;&#97;&#114;&#x67;&#x65;&#x2d;&#97;&#x2d;&#108;&#108;&#109;&#x2d;&#x72;&#x65;&#x74;&#114;&#105;&#101;&#118;&#97;&#x6c;&#45;&#97;&#117;&#x67;&#x6d;&#x65;&#110;&#x74;&#x65;&#x64;&#x2d;&#105;&#x6e;&#x2d;&#99;&#111;&#x6e;&#x74;&#101;&#120;&#116;&#45;&#108;&#x65;&#x61;&#x72;&#110;&#105;&#110;&#x67;&#x2d;&#114;&#x61;&#45;&#x69;&#x63;&#108;&#45;&#x36;&#50;&#x39;&#x63;&#x32;&#54;&#x39;&#50;&#51;&#x35;&#99;&#x37;</a></p>
<p><a href="https://medium.com/@stefansipinkoski/optimizing-ai-agents-with-dynamic-few-shot-prompting-585919f694cc#:~:text=Dynamic%20few,hand">[24]</a> <a href="https://medium.com/@stefansipinkoski/optimizing-ai-agents-with-dynamic-few-shot-prompting-585919f694cc#:~:text=relevant%2C%20thereby%20improving%20the%20model%E2%80%99s,shot%20prompting%20aims%20to%20achieve">[25]</a> Improve AI with Dynamic Few-Shot Prompting | Medium</p>
<p><a href="&#x6d;&#x61;&#x69;&#x6c;&#x74;&#111;&#58;&#x68;&#x74;&#116;&#x70;&#x73;&#x3a;&#x2f;&#x2f;&#x6d;&#x65;&#x64;&#105;&#x75;&#x6d;&#46;&#x63;&#x6f;&#109;&#x2f;&#x40;&#115;&#x74;&#101;&#102;&#x61;&#x6e;&#x73;&#105;&#x70;&#x69;&#110;&#107;&#x6f;&#x73;&#107;&#105;&#47;&#111;&#112;&#116;&#105;&#x6d;&#105;&#122;&#105;&#110;&#103;&#x2d;&#97;&#105;&#45;&#97;&#103;&#x65;&#110;&#x74;&#x73;&#45;&#x77;&#x69;&#x74;&#104;&#x2d;&#100;&#121;&#x6e;&#x61;&#109;&#x69;&#x63;&#x2d;&#x66;&#x65;&#119;&#45;&#115;&#104;&#111;&#116;&#x2d;&#112;&#x72;&#111;&#x6d;&#x70;&#x74;&#105;&#x6e;&#103;&#x2d;&#53;&#x38;&#53;&#57;&#49;&#57;&#x66;&#54;&#57;&#x34;&#99;&#x63;">&#x68;&#x74;&#116;&#x70;&#x73;&#x3a;&#x2f;&#x2f;&#x6d;&#x65;&#x64;&#105;&#x75;&#x6d;&#46;&#x63;&#x6f;&#109;&#x2f;&#x40;&#115;&#x74;&#101;&#102;&#x61;&#x6e;&#x73;&#105;&#x70;&#x69;&#110;&#107;&#x6f;&#x73;&#107;&#105;&#47;&#111;&#112;&#116;&#105;&#x6d;&#105;&#122;&#105;&#110;&#103;&#x2d;&#97;&#105;&#45;&#97;&#103;&#x65;&#110;&#x74;&#x73;&#45;&#x77;&#x69;&#x74;&#104;&#x2d;&#100;&#121;&#x6e;&#x61;&#109;&#x69;&#x63;&#x2d;&#x66;&#x65;&#119;&#45;&#115;&#104;&#111;&#116;&#x2d;&#112;&#x72;&#111;&#x6d;&#x70;&#x74;&#105;&#x6e;&#103;&#x2d;&#53;&#x38;&#53;&#57;&#49;&#57;&#x66;&#54;&#57;&#x34;&#99;&#x63;</a></p>
